<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Using WildFly Elytron with the Netty HttpServerCodec</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nlSPCVbdN9w/using-wildfly-elytron-with-netty.html" /><category term="authentication" scheme="searchisko:content:tags" /><category term="Basic" scheme="searchisko:content:tags" /><category term="Elytron" scheme="searchisko:content:tags" /><category term="feed_group_name_jbossas" scheme="searchisko:content:tags" /><category term="feed_name_darrans_wildfly_blog" scheme="searchisko:content:tags" /><category term="HTTP" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="netty" scheme="searchisko:content:tags" /><author><name>Darran Lofthouse</name></author><id>searchisko:content:id:jbossorg_blog-using_wildfly_elytron_with_the_netty_httpservercodec</id><updated>2019-01-19T17:05:25Z</updated><published>2019-01-19T17:05:00Z</published><content type="html">The WildFly Elytron project was developed to meet the needs if the WildFly application server, however the APIs and SPIs within this project also allow us to use the project in other environments.&lt;br /&gt;&lt;br /&gt;A couple of previous blogs from Farah Juma and myself have highlighted a couple of these environments already: -&lt;br /&gt;&amp;nbsp;&lt;a href="https://darranl.blogspot.com/2017/09/using-wildfly-elytron-with-undertow.html" target="_blank"&gt;Using WildFly Elytron with Undertow Standalone&lt;/a&gt;&lt;br /&gt;&amp;nbsp;&lt;a href="https://developer.jboss.org/people/fjuma/blog/2019/01/07/securing-an-embedded-jetty-server-using-elytron" target="_blank"&gt;Securing an embedded Jetty server using Elytron&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Also I have previously published a blog describing how to implement a custom HTTP authentication mechanism using the WildFly Elytron SPIs.&lt;br /&gt;&lt;a href="https://darranl.blogspot.com/2018/02/wildfly-elytron-implementing-custom.html" target="_blank"&gt;WildFly Elytron - Implementing a Custom HTTP Authentication Mechanism&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Being able to take a single security project and use it in multiple environments has numerous benefits, some of which are: -&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Only needing to learn one framework instead of one framework per server type.&lt;/li&gt;&lt;li&gt;Portability of custom implementation such as authentication mechanisms or security realms which can be used in all environments.&lt;/li&gt;&lt;li&gt;The ability to combine multiple servers into a single process whilst using common security SPIs.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;This blog post is to introduce the integration of WildFly Elytron with the Netty HttpServerCodec for HTTP authentication.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;It is worth noting this integration is specifically making use of Netty's &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;HttpServerCodec&lt;/span&gt; for integration, if an alternative HTTP server was developed on Netty then an alternative integration with WildFly Elytron would also be required.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The project containing the Netty integration code can be found on GitHub at&amp;nbsp;&lt;a href="https://github.com/wildfly-security/elytron-web-netty" target="_blank"&gt;elytron-web-netty&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;As an integration project this project only exposes once class as public API '&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;org.wildfly.elytron.web.netty.server.ElytronHandlers&lt;/span&gt;'&amp;nbsp; - the purpose this class is to take configured WildFly Elytron components and use them to insert a set of handlers into a Netty ChannelPipeline, once inserted they will perform authentication kaing use of Wildfly Elytron.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The example project can be found on GitHub at&amp;nbsp;&lt;a href="https://github.com/wildfly-security-incubator/elytron-examples/tree/master/netty-standalone" target="_blank"&gt;netty-standalone&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;After checking out the example project it can be built using maven: -&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;mvn clean instal&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;And then once build can also be executed using maven: -&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&amp;nbsp; &amp;nbsp; &lt;span style="color: lime; font-family: inherit;"&gt;mvn exec:exec&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once running you can navigate to&amp;nbsp;&lt;a href="http://localhost:7776/" target="_blank"&gt;http://localhost:7776/&lt;/a&gt;&amp;nbsp;and access the application using the username 'alice' with the password 'alice123+', if successful you should see the following response: -&lt;/div&gt;&lt;br /&gt;&lt;pre style="overflow-wrap: break-word; white-space: pre-wrap;"&gt;&lt;span style="color: lime;"&gt;Current identity 'alice'&lt;/span&gt;&lt;/pre&gt;&lt;pre style="overflow-wrap: break-word; white-space: pre-wrap;"&gt;&lt;br /&gt;&lt;/pre&gt;Now that the example project is running we can look into the details as to how WildFly Elytron was activated.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Activation&lt;/h3&gt;&lt;div&gt;Within Netty a &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ChannelInitializer&lt;/span&gt; is required to add the handlers to the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ChannelPipeline&lt;/span&gt;, within the example project this is within the class '&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;org.wildfly.security.examples.TestInitialiser&lt;/span&gt;' and is implemented as: -&lt;br /&gt;&lt;div&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;protected void initChannel(SocketChannel ch) throws Exception {&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; ChannelPipeline pipeline = ch.pipeline();&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; pipeline.addLast(new HttpServerCodec());&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; pipeline.addLast(new HttpServerExpectContinueHandler());&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; securityHandler.apply(pipeline);&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; pipeline.addLast(new TestContentHandler());&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;}&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The 'securityHandler' within the example block of code is actually an instance of the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ElytronHandlers&lt;/span&gt; class, it is worth noting that it can be cached and re-used potentially performing many initialisations concurrently.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;As the example projects starts up the&amp;nbsp;&lt;span style="color: lime; font-family: &amp;quot;Courier New&amp;quot;, Courier, monospace;"&gt;ElytronHandlers&lt;/span&gt;&amp;nbsp;is initialised as follows: -&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ElytronHandlers securityHandlers = ElytronHandlers.newInstance()&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .setSecurityDomain(securityDomain)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .setFactory(createHttpAuthenticationFactory())&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .setMechanismConfigurationSelector(MechanismConfigurationSelector.constantSelector(&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; MechanismConfiguration.builder()&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .addMechanismRealm(MechanismRealmConfiguration.builder().setRealmName("Elytron Realm").build())&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; .build()));&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This initialisation takes a pre-configured &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;SecurityDomain&lt;/span&gt; and &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;HttpAuthenticationFactory&lt;/span&gt; and adds a &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;MechanismConfigurationSelector&lt;/span&gt;, these have been covered on prior blogs so I am not going to cover the details of these again here although they can all be seen within the&amp;nbsp;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;org.wildfly.security.examples.HelloWorld&lt;/span&gt; class to see how these are initialised.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;One further method not used in this example is: -&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;public ElytronHandlers setAuthenticationRequired(final Predicate&amp;lt;HttpRequest&amp;gt; authenticationRequired)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This can be used to add a &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;Predicate&lt;/span&gt; to decide on a request by request basis if authentication is required after inspecting the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;HttpRequest&lt;/span&gt;.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;Outcome&lt;/h3&gt;&lt;div&gt;After the initialisation described above the channel end up with the following handlers defined on it's pipeline: -&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-qzwr_ggP7gU/XENVCQWyo5I/AAAAAAAAF4k/po89IXk3p4IFJ8B2rltpIiOD46oHLdfqACLcBGAs/s1600/Netty%2BHandlers%2B%25281%2529.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="413" data-original-width="547" height="481" src="https://4.bp.blogspot.com/-qzwr_ggP7gU/XENVCQWyo5I/AAAAAAAAF4k/po89IXk3p4IFJ8B2rltpIiOD46oHLdfqACLcBGAs/s640/Netty%2BHandlers%2B%25281%2529.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div&gt;For a request after being handled by the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;HttpServerCodec&lt;/span&gt; handler it will pass so the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ElytronInboundHandler&lt;/span&gt;, this is where the authentication by WildFly Elytron takes place and a &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;SecurityIdentity&lt;/span&gt; is established.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;If authentication fails the request can be turned around at this stage and sent back to the client.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Our next inbound handler is the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ElytronRunAsHandler&lt;/span&gt;, this handler is responsible for taking any established &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;SecurityIdentity&lt;/span&gt; and ensuring it is associated with the current thread.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In this set up we have one outbound handler which is the &lt;span style="color: lime; font-family: Courier New, Courier, monospace;"&gt;ElytronOutboundHandler&lt;/span&gt;, this handler is called for all messages being sent back to the client is responsible for setting any security related HTTP headers that need to be set on the respone message.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;Contribution&lt;/h3&gt;&lt;div&gt;The Netty integration project is currently tagged as a Beta as a number of areas still need to be developed, if anyone is interested in contributing their contributions will be welcome.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Completing the implementation of the ElytronHttpExchange class: -&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;Support for all Scope types.&lt;/li&gt;&lt;li&gt;Parsing of request parameters.&lt;/li&gt;&lt;li&gt;Cookie support.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;Request InputStream handling.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Improved response OutputStream handling.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Adding support for authorization, either role based checks or Java permission checks.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Further enhancement of the test cases including adding more mechanisms to be tested.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Outside of the Netty integration there are other projects out there still possible options for integration, some of these are: -&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;Tomcat&lt;/li&gt;&lt;li&gt;Pure servlet integration.&lt;/li&gt;&lt;li&gt;EE Security integration.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;For all integrations some form of common testsuite to verify the full permutation of authentication mechanisms available within WildFly Elytron.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nlSPCVbdN9w" height="1" width="1" alt=""/&gt;</content><summary>The WildFly Elytron project was developed to meet the needs if the WildFly application server, however the APIs and SPIs within this project also allow us to use the project in other environments. A couple of previous blogs from Farah Juma and myself have highlighted a couple of these environments already: -  Using WildFly Elytron with Undertow Standalone  Securing an embedded Jetty server using E...</summary><dc:creator>Darran Lofthouse</dc:creator><dc:date>2019-01-19T17:05:00Z</dc:date><feedburner:origLink>http://darranl.blogspot.com/2019/01/using-wildfly-elytron-with-netty.html</feedburner:origLink></entry><entry><title>Teiid Runtimes Explained</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VJHRGur2ouw/teiid-runtimes-explained.html" /><category term="feed_group_name_teiid" scheme="searchisko:content:tags" /><category term="feed_name_teiid" scheme="searchisko:content:tags" /><author><name>Ramesh Reddy</name></author><id>searchisko:content:id:jbossorg_blog-teiid_runtimes_explained</id><updated>2019-01-18T22:35:57Z</updated><published>2019-01-18T22:35:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;If you have been following &lt;a href="https://teiid.io/"&gt;Teiid&lt;/a&gt; lately we have been going through a whole lot of renovations. Yes, renovations or reorganization or refactoring or whatever you want to call it. Basically, we are making Teiid more modular with fewer dependencies that can be used by however your use case&amp;nbsp;dictates rather than use it as one monolith&amp;nbsp;application deployed into WildFly JEE Application Server. There is nothing wrong in using Teiid as server&amp;nbsp;model, but with the proliferation&amp;nbsp;of container-based workloads and cloud-based&amp;nbsp;architectures, the previous server-based model does not work or simply won't scale. So, we needed to think of alternatives, thus Teiid team introduced a couple different versions modular Teiid what we are calling as "Teiid Runtimes".&lt;br /&gt;&lt;br /&gt;Note that in these modular Teiid runtimes, not all the features you were used to using&amp;nbsp;in Teiid Server model may not be there but you will have extensions to add in those that are most appropriate for your domain. If you are looking for a data virtualization system in any configuration, one of below should satisfy your needs.&lt;br /&gt;&lt;br /&gt;Now that we know what Teiid is up to, what are different flavors of these Runtimes? Basically, we have four different varieties.&lt;br /&gt;&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;Teiid Server with &lt;a href="http://wildfly.org/"&gt;WildFly&lt;/a&gt; (legacy model)&lt;/li&gt;&lt;li&gt;Teiid&amp;nbsp;Embedded&lt;/li&gt;&lt;li&gt;Teiid &lt;a href="https://spring.io/projects/spring-boot"&gt;Spring Boot&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Teiid &lt;a href="https://thorntail.io/"&gt;Thorntail&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Teiid Server on WildFly&lt;/h3&gt;&lt;div&gt;This is the legacy runtime that Teiid team has been supporting for a while, the support for this will be continuing to new versions of WildFly. Currently, with the release of &lt;a href="http://teiid.io/teiid_runtimes/teiid_wildfly/downloads/"&gt;Teiid 12.0&lt;/a&gt;, the WildFly support is at &lt;a href="http://wildfly.org/downloads/"&gt;WildFly 14.&lt;/a&gt;&amp;nbsp; Going forward there will be a separate repo for the WildFly based deployments that is different&amp;nbsp;from current Teiid git repo. This repository will contain only code that is specific to WildFly. To use this version one needs to be little knowledgable in WildFly server, but typically no Java experience is needed but recommended.&amp;nbsp; If you want you can build Docker images based on this as a Server just like say MySQL or PostgreSQL image.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid/tree/master/wildfly"&gt;GitRepo&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-quickstarts"&gt;Examples&lt;/a&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Teiid Embedded&lt;/h3&gt;&lt;div&gt;I would call this and rest of other runtimes below as "frameworks" where they do not provide a fully functioning system, but Teiid provides the essential APIs and hooks to design your own system with ease. Teiid Embedded is the plainest version of all, where you have a whole lot of autonomy to design to your use case and embed Teiid in your own JVM. There are plenty of examples to you started. When using this Java experience is required. This is ideal for anyone wanting to embed in their own project/product in OEM fashion.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid"&gt;GitRepo&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-embedded-examples"&gt;Examples&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Teiid Spring Boot&lt;/h3&gt;&lt;div&gt;It is no secret that Spring Boot most popular among Java developers. This runtime uses Spring Boot and Teiid Embedded&amp;nbsp;to bring Data Virtualization features for Java developer in a way that they are already familiar to them. For example, it is as simple as using JPA framework. This one is my current favorite, as this supports legacy VDB file based deployments and also JPA based view definitions where explicit VDB does not need to be defined. It also has a feature&amp;nbsp;called "redirection", where it can make it possible to use production data for testing without modifying it. If you are Spring Boot developer there is not much more you need to learn as most of the Data Virtualization will be instrumented in by using a set of annotations. This would be an ideal framework to use if you are thinking of using Teiid in Microservices architecture. If you are looking into container-based deployments and cloud architectures this is an ideal platform. The examples will show how to deploy into OpenShift or Kubernetes using &lt;a href="https://maven.fabric8.io/"&gt;fabric8-maven-plugin&lt;/a&gt;.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;There is limited support for different sources currently we only support &lt;a href="https://github.com/teiid/teiid-spring-boot/tree/master/samples/rdbms-file"&gt;relational sources&lt;/a&gt;, &lt;a href="https://github.com/teiid/teiid-spring-boot/tree/master/samples/excel"&gt;excel&lt;/a&gt;, &lt;a href="https://github.com/teiid/teiid-spring-boot/tree/master/samples/rest"&gt;REST&lt;/a&gt;. But this support will be expanding.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-spring-boot"&gt;GitRepo&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-spring-boot/tree/master/samples"&gt;Examples&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Teiid Thorntail&lt;/h3&gt;&lt;div&gt;Thorntail is a Microprofile based Java framework that is designed for Java-based Microservices using standards-based technologies. Thorntail was previously named "WildFly Swarm".&amp;nbsp; Since this Thorntail 2.x technology was mostly based on WildFly there good support for most of the features that were available in Teiid Server. We will continue to support 2.x Thorntail.&amp;nbsp; If you want a system close to WildFly technology but in embedded Microservice style application then choose this version. this version is also good for using as container-based workloads for cloud environments. This supports similar features as spring boot in this area.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;When Thorntail 4.x rolls around we have to reevaluate the support there as that is assumed to be vastly different from Thorntail 2.x, and we expect that would be a complete rewrite.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-thorntail"&gt;GitRepo&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;a href="https://github.com/teiid/teiid-thorntail/tree/master/examples"&gt;Examples&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;What about UI?&lt;/h3&gt;&lt;div&gt;As you probably noticed the pace of Teiid Designer releases stopped, as we are not putting in any more work into eclipse based tooling. The existing Teiid Designer should be still valid to use in the design of your VDBs if you prefer as they VDB you build will be deployable in any of the above Teiid Runtimes. However, Teiid Runtimes also support dynamic VDBs that one can build by hand or programmatically.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;We are also collaborating/integrating Teiid technology with Syndesis community, there you will see a UI to build and deploy Teiid based runtime. More on this later in future blogs.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Let us know your&amp;nbsp;opinion as we shape Teiid for future workloads while supporting the legacy.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Ramesh..&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VJHRGur2ouw" height="1" width="1" alt=""/&gt;</content><summary>If you have been following Teiid lately we have been going through a whole lot of renovations. Yes, renovations or reorganization or refactoring or whatever you want to call it. Basically, we are making Teiid more modular with fewer dependencies that can be used by however your use case dictates rather than use it as one monolith application deployed into WildFly JEE Application Server. There is n...</summary><dc:creator>Ramesh Reddy</dc:creator><dc:date>2019-01-18T22:35:00Z</dc:date><feedburner:origLink>http://teiid.blogspot.com/2019/01/teiid-runtimes-explained.html</feedburner:origLink></entry><entry><title>Integration of storage services (part 6)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/hzH3HyLehQ0/" /><category term="Agile Integration" scheme="searchisko:content:tags" /><category term="Architecture" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="Customer Experience" scheme="searchisko:content:tags" /><category term="developer" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Red Hat Customers" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="storage" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-integration_of_storage_services_part_6</id><updated>2019-01-18T21:40:38Z</updated><published>2019-01-18T21:40:38Z</published><content type="html">&lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/"&gt;Part 5 this series&lt;/a&gt;, we looked into details that determine how your integration becomes the key to transforming your customer experience.&lt;/p&gt; &lt;p&gt;It started with laying out the process of how I&amp;#8217;ve approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Now it&amp;#8217;s time to cover various blueprint details.&lt;/p&gt; &lt;p&gt;This article covers the final elements in the blueprint, &lt;i&gt;storage services, &lt;/i&gt;which are fundamental to the generic architectural overview.&lt;/p&gt; &lt;p&gt;&lt;span id="more-554507"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Architectural details&lt;/h2&gt; &lt;p&gt;As mentioned before, the architectural details covered here are base on real customer integration solutions using open source technologies. The elements presented here are then the &lt;i&gt;generic common architectural elements&lt;/i&gt; that I&amp;#8217;ve identified and collected in a generic architectural blueprint. It&amp;#8217;s my intent to provide a blueprint that provides guidance and not deep technical details.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57.png"&gt;&lt;img class=" aligncenter wp-image-555447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57-1024x163.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57-1024x163.png" alt="Storage services" width="640" height="102" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57-1024x163.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57-300x48.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57-768x122.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.47.57.png 1110w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Note that we&amp;#8217;re covering the visual representations as presented, but it&amp;#8217;s expected that they&amp;#8217;ll be evolving visually over time. There are many ways to represent each element in this architectural blueprint, but I&amp;#8217;ve chosen icons, text, and colors that I hope are going to make it all easy to absorb. Feel free to post comments at the bottom of this post, or &lt;a href="https://www.schabell.org/p/contact.html" target="_blank" rel="noopener"&gt;contact me directly&lt;/a&gt; with your feedback.&lt;/p&gt; &lt;p&gt;Now let&amp;#8217;s take a look at the details in this architecture and outline the elements uncovered in my research.&lt;/p&gt; &lt;h2&gt;Storage&lt;/h2&gt; &lt;p&gt;While every organization needs and certainly has chosen one or more the storage services described in this article, for completeness, I&amp;#8217;ve presented the most common choices found in my research.&lt;/p&gt; &lt;p&gt;The basic legacy solution every organization I researched had was a &lt;i&gt;virtual block storage (VBS)&lt;/i&gt; solution. It can be in your data center, on site in your developer machine, or hosted by almost any cloud provider. It provides the fixed-size raw storage capacity and must have consistent I/O performance with low-latency connectivity.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.37.52.png"&gt;&lt;img class=" aligncenter wp-image-555457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.37.52.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.37.52.png" alt="Virtual block storage" width="332" height="49" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.37.52.png 332w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.37.52-300x44.png 300w" sizes="(max-width: 332px) 100vw, 332px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When files and data sets become very large, then &lt;i&gt;object-based storage (OBS) &lt;/i&gt;becomes the service of choice. It&amp;#8217;s available on-premises or as services hosted by most cloud providers to ensure you can leverage the persistence of your choice for your specific use case.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.10.png"&gt;&lt;img class=" aligncenter wp-image-555467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.10.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.10.png" alt="Object-based storage" width="333" height="47" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.10.png 333w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.10-300x42.png 300w" sizes="(max-width: 333px) 100vw, 333px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For container-based applications and services, persistence is achieved with &lt;i&gt;container-native storage (CNS)&lt;/i&gt; solutions. As previously mentioned, central to all research I conducted was a distinct leaning towards the use of a &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;container&lt;/a&gt; platform for applications and &lt;a href="https://developers.redhat.com/blog/category/microservices/"&gt;microservices&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.02.png"&gt;&lt;img class=" aligncenter wp-image-555477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.02.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.02.png" alt="Container-native storage" width="331" height="45" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.02.png 331w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/Screenshot-2018-12-21-at-10.38.02-300x41.png 300w" sizes="(max-width: 331px) 100vw, 331px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;A need for storage for these container-based elements leads organizations to search for CNS solutions. Such a solution is native to the container platform and delivers the performance and ease of use desired by developers and architects constructing the integration solutions for omnichannel.&lt;/p&gt; &lt;p&gt;One key to our generic integration with these storage services lies in the previously discussed &lt;i&gt;integration data microservices&lt;/i&gt; that make all forms of storage services available across your architecture. These details are not all-telling, but should give you the guidance you&amp;#8217;d need to get started in your own architectural situations.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s next&lt;/h2&gt; &lt;p&gt;This overview covers the container platform elements that make up our architecture blueprint for the omnichannel customer experience use case.&lt;/p&gt; &lt;p&gt;An overview of the series on omnichannel customer experience portfolio architecture blueprint can be found here:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/28/integration-is-key-to-customer-experience/"&gt;Part 1: How integration is key to customer experience&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/30/common-architectural-elements-for-modern-integration-architectures/"&gt;Part 2: Common architectural elements for modern integration architectures&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/14/integration-of-external-application-details-part-3/"&gt;Part 3: Integration of external application details&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/20/integration-of-api-management-details-part-4/"&gt;Part 4: Integration of API management details&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/01/04/integration-of-container-platform-essentials-part-5/" target="_blank" rel="noopener"&gt;Part 5: Integration of container platform essentials&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 6: Integration of storage services (this article)&lt;/li&gt; &lt;li&gt;Part 7: Application integration details&lt;/li&gt; &lt;li&gt;Part 8: Dissecting several specific application integration architectures&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Catch up on any articles you missed by following one of the links above.&lt;/p&gt; &lt;p&gt;Next in this series, we start taking a look at specific integration architectures that tie in all the elements we&amp;#8217;ve discussed as part of a specific case in an architecture for omnichannel customer experience.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#38;linkname=Integration%20of%20storage%20services%20%28part%206%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F18%2Fintegration-of-storage-services-part-6%2F&amp;#038;title=Integration%20of%20storage%20services%20%28part%206%29" data-a2a-url="https://developers.redhat.com/blog/2019/01/18/integration-of-storage-services-part-6/" data-a2a-title="Integration of storage services (part 6)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/18/integration-of-storage-services-part-6/"&gt;Integration of storage services (part 6)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/hzH3HyLehQ0" height="1" width="1" alt=""/&gt;</content><summary>In Part 5 this series, we looked into details that determine how your integration becomes the key to transforming your customer experience. It started with laying out the process of how I’ve approached the use case by researching successful customer portfolio solutions as the basis for a generic architectural blueprint. Now it’s time to cover various blueprint details. This article covers the fina...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-01-18T21:40:38Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/18/integration-of-storage-services-part-6/</feedburner:origLink></entry><entry><title>FaaS tutorial 2: Set up Google Cloud Function</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/k0PAOpM4rlg/faas-tutorial-2-set-up-google-cloud.html" /><category term="feed_group_name_aerogear" scheme="searchisko:content:tags" /><category term="feed_name_corinnekrych" scheme="searchisko:content:tags" /><author><name>Corinne Krych</name></author><id>searchisko:content:id:jbossorg_blog-faas_tutorial_2_set_up_google_cloud_function</id><updated>2019-01-18T10:33:00Z</updated><published>2019-01-18T10:33:00Z</published><content type="html">Now that we have deployed an app in &lt;a href="http://corinnekrych.blogspot.com/2019/01/faas-tutorial-1-start-with-firebase-and.html"&gt;FaaS tutorial 1: Start with Firebase and prepare the ground&lt;/a&gt;, time to spice up ️ our basic app to add some back-end stuff. &lt;br/&gt;&lt;br/&gt;What about defining a REST API to add a new record to the database. We'll use HTTP triggered functions. There are different kind of triggers for different use cases, we dig into that in the next post. &lt;br/&gt;&lt;br/&gt;Let's start out tutorial, as always step by steps ! &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 1: init function&lt;/h2&gt;For your project to use Google Cloud Functions (GCF), use firebase cli to configure it. Simply run the command: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ firebase init functions&lt;br /&gt;&lt;br /&gt; ######## #### ######## ######## ######## ### ###### ########&lt;br /&gt; ## ## ## ## ## ## ## ## ## ## ##&lt;br /&gt; ###### ## ######## ###### ######## ######### ###### ######&lt;br /&gt; ## ## ## ## ## ## ## ## ## ## ##&lt;br /&gt; ## #### ## ## ######## ######## ## ## ###### ########&lt;br /&gt;&lt;br /&gt;You're about to initialize a Firebase project in this directory:&lt;br /&gt;&lt;br /&gt; /Users/corinne/workspace/test-crud2&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;=== Project Setup&lt;br /&gt;&lt;br /&gt;First, let's associate this project directory with a Firebase project.&lt;br /&gt;You can create multiple project aliases by running firebase use --add, &lt;br /&gt;but for now we'll just set up a default project.&lt;br /&gt;&lt;br /&gt;? Select a default Firebase project for this directory: test-83c1a (test)&lt;br /&gt;i Using project test-83c1a (test)&lt;br /&gt;&lt;br /&gt;=== Functions Setup&lt;br /&gt;&lt;br /&gt;A functions directory will be created in your project with a Node.js&lt;br /&gt;package pre-configured. Functions can be deployed with firebase deploy.&lt;br /&gt;&lt;br /&gt;? What language would you like to use to write Cloud Functions? JavaScript&lt;br /&gt;? Do you want to use ESLint to catch probable bugs and enforce style? No&lt;br /&gt;✔ Wrote functions/package.json&lt;br /&gt;✔ Wrote functions/index.js&lt;br /&gt;✔ Wrote functions/.gitignore&lt;br /&gt;? Do you want to install dependencies with npm now? Yes&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;Below the ascii art Firebase gets chatty and tells you all about it's doing. &lt;br/&gt;Once you've selected a firebase project (select the one we created in tutorial 1 with the firestore setup), you use default options (JavaScript, no ESLint). &lt;br/&gt;&lt;br/&gt;&lt;div style="border-style: solid;border-color:lightgrey;background: lightgrey;padding:1em"&gt;&lt;strong&gt;Note:&lt;/strong&gt;By default, GCF runs on node6, if you want to enable node8, in your &lt;code&gt;/functions/package.json&lt;/code&gt; add the following json at root level: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;"engines": {&lt;br /&gt; "node": "8"&lt;br /&gt; }&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;You will need node8 for the rest of the tutorial as we use &lt;code&gt;async&lt;/code&gt; instead of Promises syntax. &lt;/div&gt;Firebase has created a default package with an initial GCF bootstrap in &lt;code&gt;functions/index.js&lt;/code&gt;. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 2: HelloWorld&lt;/h2&gt;Go to &lt;code&gt;functions/index.js&lt;/code&gt; and uncomment the helloWorld function &lt;pre&gt;&lt;code class="language-JavaScript"&gt;exports.helloWorld = functions.https.onCall((request, response) =&gt; {&lt;br /&gt; response.send("Hello from Firebase!");&lt;br /&gt;});&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;This is a basic helloWorld function, we'll use just to get use to deploying functions. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 3: deploy&lt;/h2&gt;Again, use firebase cli and type the command: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ firebase deploy --only functions&lt;br /&gt;✔ functions[helloWorld(us-central1)]: Successful update operation. &lt;br /&gt;✔ Deploy complete!&lt;br /&gt;&lt;br /&gt;Please note that it can take up to 30 seconds for your updated functions to propagate.&lt;br /&gt;Project Console: https://console.firebase.google.com/project/test-83c1a/overview&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;Note you call also deploy just our functions by adding &lt;code&gt;firebase deploy --only functions:myFunctionName&lt;/code&gt;. &lt;br/&gt;If you go to the Firebase console and then in the function tab, you will find the URL where your function is available. &lt;br/&gt;&lt;br/&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-4nMIxvZ_ir8/XEGZdKcAGUI/AAAAAAAADKU/7zibVG1a9-Y5d9ku78UCqSvDPkSYknv4gCLcBGAs/s1600/helloWorld-functions.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://2.bp.blogspot.com/-4nMIxvZ_ir8/XEGZdKcAGUI/AAAAAAAADKU/7zibVG1a9-Y5d9ku78UCqSvDPkSYknv4gCLcBGAs/s640/helloWorld-functions.png" width="640" height="193" data-original-width="1240" data-original-height="374" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 3: try it&lt;/h2&gt;Since it's an HTTP triggered function, let's trying with &lt;code&gt;curl&lt;/code&gt;: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ curl https://us-central1-test-83c1a.cloudfunctions.net/helloWorld&lt;br /&gt;Hello from Firebase!&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;You've deployed and tried your first cloud function. &lt;br/&gt;Let's now try to fulfil the same use-case as per tutorial 1: We want an HTTP triggered function than insert 2 fields in a database collection. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 4: onRequest function to insert in DB&lt;/h2&gt;&lt;ul&gt;&lt;li&gt; In &lt;code&gt;function/index.js&lt;/code&gt; add the function below: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;const admin = require('firebase-admin');&lt;br /&gt;admin.initializeApp(); // [2]&lt;br /&gt;&lt;br /&gt;exports.insertOnRequest = functions.https.onRequest(async (req, res) =&gt; {&lt;br /&gt; const field1 = req.query.field1; // [2] &lt;br /&gt; const field2 = req.query.field2;&lt;br /&gt; const writeResult = await admin.firestore().collection('items').add({field1: field1, field2: field2}); // [3]&lt;br /&gt; res.json({result: `Message with ID: ${writeResult.id} added.`}); // [4]&lt;br /&gt;});&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;&lt;ul&gt;&lt;li&gt;[1]: import the Firebase Admin SDK to access the Firestore database and initialize with default values.&lt;/li&gt;&lt;li&gt;[2]: extract data from query param.&lt;/li&gt;&lt;li&gt;[3]: add the new message into the Firestore Database using the Firebase Admin SDK.&lt;/li&gt;&lt;li&gt;[4]: send back the id of the newly inserted record.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Deploy it with &lt;code&gt;firebase deploy --only functions&lt;/code&gt;. This will redeploy both functions.&lt;/li&gt;&lt;li&gt; Test it by curling: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ curl https://us-central1-test-83c1a.cloudfunctions.net/insertOnRequest\?field1\=test1\&amp;field2\=test2&lt;br /&gt;{"result":"Message with ID: b5Nw8U3wraQhRqJ0vMER added."}&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;Wow! Even better, you've deployed a cloud function that does something &lt;br/&gt;&lt;br/&gt;Note thatif your use-case is to call a cloud function from your UI, you can &lt;code&gt;onCall&lt;/code&gt; CGF. Some of the boiler plate around security is taken care for you. Let's try to add an onCall function! &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 5: onCall function to insert in DB&lt;/h2&gt;&lt;ul&gt;&lt;li&gt; In &lt;code&gt;function/index.js&lt;/code&gt; add the function below: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;exports.insertOnCall = functions.https.onCall(async (data, context) =&gt; {&lt;br /&gt; console.log(`insertOnCall::Add to database ${JSON.stringify(data)}`);&lt;br /&gt; const {field1, field2} = data;&lt;br /&gt; await admin.firestore().collection('items').add({field1, field2});&lt;br /&gt;});&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt;Deploy it with &lt;code&gt;firebase deploy --only functions&lt;/code&gt;. This will redeploy both functions.&lt;/li&gt;&lt;li&gt; Test it in your UI code. In &lt;a href=""&gt;tutorial 1, step5&lt;/a&gt; we defined a Create component in &lt;code&gt;src/component/index.js&lt;/code&gt;, let's revisit the &lt;code&gt;onSumit&lt;/code&gt; method: &lt;pre&gt;&lt;code class="language-JavaScript"&gt;onSubmit = (e) =&gt; {&lt;br /&gt; e.preventDefault();&lt;br /&gt; // insert by calling cloud function&lt;br /&gt; const insertDB = firebase.functions().httpsCallable('insertOnCall'); // [1]&lt;br /&gt; insertDB(this.state).then((result) =&gt; { // [2]&lt;br /&gt; console.log(`::Result is ${JSON.stringify(result)}`);&lt;br /&gt; this.setState({&lt;br /&gt; field1: '',&lt;br /&gt; field2: '',&lt;br /&gt; });&lt;br /&gt; this.props.history.push("/")&lt;br /&gt; }).catch((error) =&gt; {&lt;br /&gt; console.error("Error adding document: ", error);&lt;br /&gt; });&lt;br /&gt; };&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;In [1] we passed the name of the function to retrieve a reference, we simply call this function in [2] with json object containing all the fields we need. &lt;/li&gt;&lt;/ul&gt;&lt;br/&gt;&lt;h2&gt;Where to go from here?&lt;/h2&gt;In this tutorial, you've get acquainted with google function in its most simple form: http triggered. To go further into learning how to code GCF, the best way is to look at existing code: the &lt;a href="https://github.com/firebase/functions-samples"&gt;firebase/functions-samples&lt;/a&gt; on GitHub is the perfect place to explore. &lt;br/&gt;In next tutorials we'll explore the different use-cases that fit best a cloud function. &lt;br/&gt;&lt;br/&gt;Stay tuned!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/k0PAOpM4rlg" height="1" width="1" alt=""/&gt;</content><summary>Now that we have deployed an app in FaaS tutorial 1: Start with Firebase and prepare the ground, time to spice up ️ our basic app to add some back-end stuff. What about defining a REST API to add a new record to the database. We'll use HTTP triggered functions. There are different kind of triggers for different use cases, we dig into that in the next post. Let's start out tutorial, as always step ...</summary><dc:creator>Corinne Krych</dc:creator><dc:date>2019-01-18T10:33:00Z</dc:date><feedburner:origLink>http://corinnekrych.blogspot.com/2019/01/faas-tutorial-2-set-up-google-cloud.html</feedburner:origLink></entry><entry><title>FaaS tutorial 1: Start with Firebase and prepare the ground</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OeJQJXRTl-M/faas-tutorial-1-start-with-firebase-and.html" /><category term="feed_group_name_aerogear" scheme="searchisko:content:tags" /><category term="feed_name_corinnekrych" scheme="searchisko:content:tags" /><author><name>Corinne Krych</name></author><id>searchisko:content:id:jbossorg_blog-faas_tutorial_1_start_with_firebase_and_prepare_the_ground</id><updated>2019-01-17T13:59:00Z</updated><published>2019-01-17T13:59:00Z</published><content type="html">As being an organiser of &lt;a href=""&gt;RivieraDEV&lt;/a&gt;, I was looking for a platform to host our CFP (call for paper). I've bumped into the open source project &lt;a href="https://github.com/bpetetot/conference-hall"&gt;conference-hall&lt;/a&gt; wandering on twitter (the gossip bird &lt;i&gt;is useful&lt;/i&gt; from time to time). &lt;br/&gt;&lt;br/&gt;The app is nicely crafted and could be used free, even better I've learned afterward, there is an hosted version! That's the one I wanted to use but we were missing one key feature: sending email to inform speaker of the deliberations and provide a way for speakers to confirm their venue. &lt;br/&gt;&lt;br/&gt;Open Source Project? Let's make the world better by contributing... &lt;br/&gt;&lt;br/&gt;On a first look, conference-hall is a web app deployed on Google Cloud Platform. The SPA is deployed using Firebase tooling and make use of firestore database. By contributing to the project, I get acquainted to Firebase. Learning something new is cool, sharing it is even better &lt;br/&gt;&lt;br/&gt;Time to start a series of blogs post on the &lt;a href="https://en.wikipedia.org/wiki/Function_as_a_service"&gt;FaaS&lt;/a&gt; subject. I'd like to explore Google functions as a service but also go broader and see how it is implemented in open source world. &lt;br/&gt;&lt;br/&gt;In this first article, I'll share with your how to get started configuring a project from scratch in Firebase and how to deploy it to get a ground project to introduce cloud functions in the next post. Let's get started step by step... &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 1️⃣: Initialise firebase project&lt;/h2&gt;Go to &lt;a href="https://console.firebase.google.com/u/0/"&gt;Firebase console&lt;/a&gt; and Create a firebase project, let's name it &lt;code&gt;test&lt;/code&gt; &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 2️⃣: Use Firestore&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;In left-hand side menu select Database tab, then click &lt;code&gt;Create Database&lt;/code&gt;. Follow &lt;a href="https://firebase.google.com/docs/firestore/quickstart?authuser=0"&gt;Firestore documentation&lt;/a&gt; if in trouble. The Firebase console UI is quite easy to follow. Note Firestore is still beta at the time of writing.&lt;/li&gt;&lt;li&gt;Choose &lt;code&gt;Start in test mode&lt;/code&gt; then click &lt;code&gt;Enabled&lt;/code&gt; button.&lt;/li&gt;&lt;/ul&gt;You should be forwarded to the Database explorer, you can now add a new collection &lt;code&gt;items&lt;/code&gt; as below: &lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-Nt0UrxwcUcU/XDxdi53bz7I/AAAAAAAADKE/CIU_HMqVH5cMw4-1k0QpTDIV5JfGoICpACLcBGAs/s1600/unspecified-1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://1.bp.blogspot.com/-Nt0UrxwcUcU/XDxdi53bz7I/AAAAAAAADKE/CIU_HMqVH5cMw4-1k0QpTDIV5JfGoICpACLcBGAs/s640/unspecified-1.png" width="640" height="566" data-original-width="868" data-original-height="768" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;h2&gt;Step 3️⃣: Boostrap app&lt;/h2&gt;We use create-react-app to get an initial react app &lt;pre&gt;&lt;code class="language-JavaScript"&gt;npx create-react-app test-crud&lt;br /&gt;npm install --save firebase&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;and then we've added firebase SDK. &lt;br/&gt;&lt;br/&gt;&lt;h3&gt;Insert firebase config&lt;/h3&gt; &lt;ul&gt; &lt;li&gt; We use &lt;a href="https://facebook.github.io/create-react-app/docs/adding-custom-environment-variables"&gt;react-script env variable support&lt;/a&gt;&lt;/li&gt;&lt;li&gt; In &lt;code&gt;env.local&lt;/code&gt; copy variable from firebase console &lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-0w5tsyhpPLY/XDs1ljYsWtI/AAAAAAAADJ4/NgXjFWL1qwYhC1K5Ct0uuR6I6-33-A84gCPcBGAYYCw/s1600/firebase-config.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://4.bp.blogspot.com/-0w5tsyhpPLY/XDs1ljYsWtI/AAAAAAAADJ4/NgXjFWL1qwYhC1K5Ct0uuR6I6-33-A84gCPcBGAYYCw/s640/firebase-config.png" width="640" height="442" data-original-width="1084" data-original-height="748" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;/li&gt; &lt;li&gt; In &lt;code&gt;src/firebase/firebase.js&lt;/code&gt;, read env variable and initialise &lt;pre&gt;&lt;code class="language-JavaScript"&gt;const config = {&lt;br /&gt; apiKey: process.env.REACT_APP_API_KEY,&lt;br /&gt; authDomain: process.env.REACT_APP_AUTH_DOMAIN,&lt;br /&gt; databaseURL: process.env.REACT_APP_DATABASE_URL,&lt;br /&gt; projectId: process.env.REACT_APP_PROJECT_ID,&lt;br /&gt; storageBucket: process.env.REACT_APP_STARAGE_BUCKET,&lt;br /&gt; messagingSenderId: process.env.REACT_APP_MESSAGING_SENDER_ID,&lt;br /&gt;};&lt;br /&gt;firebase.initializeApp(config);&lt;br /&gt;&lt;br /&gt;firebase.firestore().settings(settings);&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt;This way you keep your secret safe, not committed in your code &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 4️⃣: Add routing&lt;/h2&gt;&lt;pre&gt;&lt;code class="language-JavaScript"&gt;npm install --save react-router-dom&lt;br /&gt;mkdir src/components&lt;br /&gt;touch src/components/create.js&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;And define route in &lt;code&gt;src/index.js&lt;/code&gt;&lt;pre&gt;&lt;code class="language-JavaScript"&gt;ReactDOM.render(&lt;br /&gt; &amp;lt;Router&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;Route exact path='/' component={App} /&amp;gt;&lt;br /&gt; &amp;lt;Route path='/create' component={Create} /&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;/Router&amp;gt;,&lt;br /&gt; document.getElementById('root')&lt;br /&gt;);&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;In the root path, we'll display the list of items. In the the &lt;code&gt;Create&lt;/code&gt; component we'll define a form component to add new items to the list. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 5️⃣: Access Firestore in the app&lt;/h2&gt;Let's define the content of &lt;code&gt;Create&lt;/code&gt; component in &lt;code&gt;src/component/index.js&lt;/code&gt;&lt;pre&gt;&lt;code class="language-JavaScript"&gt;class Create extends Component {&lt;br /&gt; constructor() {&lt;br /&gt; super();&lt;br /&gt; this.ref = firebase.firestore().collection('items'); // [1] retrieve items reference&lt;br /&gt; this.state = {&lt;br /&gt; field1: '',&lt;br /&gt; field2: '',&lt;br /&gt; };&lt;br /&gt; }&lt;br /&gt; onChange = (e) =&gt; {&lt;br /&gt; const state = this.state;&lt;br /&gt; state[e.target.name] = e.target.value;&lt;br /&gt; this.setState(state);&lt;br /&gt; };&lt;br /&gt; onSubmit = (e) =&gt; {&lt;br /&gt; e.preventDefault();&lt;br /&gt; const { field1, field2 } = this.state;&lt;br /&gt; this.ref.add({ // [2] Insert by using firestore SDK&lt;br /&gt; field1,&lt;br /&gt; field2,&lt;br /&gt; }).then((docRef) =&gt; {&lt;br /&gt; this.setState({&lt;br /&gt; field1: '',&lt;br /&gt; field2: '',&lt;br /&gt; });&lt;br /&gt; this.props.history.push("/")&lt;br /&gt; }).catch((error) =&gt; {&lt;br /&gt; console.error("Error adding document: ", error);&lt;br /&gt; });&lt;br /&gt; };&lt;br /&gt;&lt;br /&gt; render() {&lt;br /&gt; const { field1, field2 } = this.state;&lt;br /&gt; return (&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;h3&amp;gt;&lt;br /&gt; Add Item&lt;br /&gt; &amp;lt;/h3&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;h4&amp;gt;Link to="/" &amp;gt;Items List&amp;lt;/Link&amp;gt;&amp;lt;/h4&amp;gt;&lt;br /&gt; &amp;lt;form onSubmit={this.onSubmit}&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;label htmlFor="title"&amp;gt;field1:&amp;lt;/label&amp;gt;&lt;br /&gt; &amp;lt;input type="text" name="field1" value={field1} onChange={this.onChange} /&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;div&amp;gt;&lt;br /&gt; &amp;lt;label htmlFor="title"&amp;gt;field2:&amp;lt;/label&amp;gt;&lt;br /&gt; &amp;lt;input type="text" name="field2" value={field2} onChange={this.onChange} /&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;button type="submit"&amp;gt;Submit&amp;lt;/button&amp;gt;&lt;br /&gt; &amp;lt;/form&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; &amp;lt;/div&amp;gt;&lt;br /&gt; );&lt;br /&gt; }&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;export default Create;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;It seems a lot of code but the key points are [1] and [2] where we use the firestore SDK to add a new item in the database directly from the client app. the call in [2] is going to be revisited in next blog post to make usage of cloud function. &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Step 6️⃣: Deploy on firebase&lt;/h2&gt; So we build a small test app accessing firestore DB let's deploy it on the cloud with Firebase tooling ! &lt;ul&gt;&lt;li&gt; Start running a production build &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm run build&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt; Install firebase tools &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ npm install -g firebase-tools&lt;br /&gt;$ firebase login&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;li&gt; Init function &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ firebase init&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt; &lt;li&gt; Step 1: Select the Firebase features you want to use: Firestore Hosting. For now we focus only on deploying ie: hosting the app&lt;/li&gt; &lt;li&gt; Step 2: Firebase command-line interface will pull up your list of Firebase projects, where you pick firebase-crud.&lt;/li&gt; &lt;li&gt; Step 3: Keep the default for the Database Rules file name and just press enter.&lt;/li&gt; &lt;li&gt; Step 4: Pay attention to the question about public directory, which is the directory that will be deployed and served by Firebase. In our case it is &lt;code&gt;build&lt;/code&gt;, which is the folder where our production build is located. Type “build” and proceed.&lt;/li&gt; &lt;li&gt; Step 5: Firebase will ask you if you want the app to be configured as a single-page app. Say "yes".&lt;/li&gt; &lt;li&gt; Step 6: Firebase will warn us that we already have &lt;code&gt;build/index.html&lt;/code&gt;. All fine!&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt; deploy! &lt;pre&gt;&lt;code class="language-JavaScript"&gt;$ firebase deploy&lt;br /&gt;...&lt;br /&gt;✔ Deploy complete!&lt;br /&gt;&lt;br /&gt; Project Console: https://console.firebase.google.com/project/test-83c1a/overview&lt;br /&gt; Hosting URL: https://test-83c1a.firebaseapp.com&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&lt;/ul&gt; &lt;br/&gt;&lt;br/&gt;&lt;h2&gt;Where to go from there?&lt;/h2&gt; In this blog post you've seen how to configure and deploy an SPA on firebase and how to set up a Firestore DB. Next blog post, you'll see how to write you first Google Cloud Function. Stay tuned.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OeJQJXRTl-M" height="1" width="1" alt=""/&gt;</content><summary>As being an organiser of RivieraDEV, I was looking for a platform to host our CFP (call for paper). I've bumped into the open source project conference-hall wandering on twitter (the gossip bird is useful from time to time). The app is nicely crafted and could be used free, even better I've learned afterward, there is an hosted version! That's the one I wanted to use but we were missing one key fe...</summary><dc:creator>Corinne Krych</dc:creator><dc:date>2019-01-17T13:59:00Z</dc:date><feedburner:origLink>http://corinnekrych.blogspot.com/2019/01/faas-tutorial-1-start-with-firebase-and.html</feedburner:origLink></entry><entry><title>Modern web applications on OpenShift: Part 3 — Openshift as a development environment</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/siuhebeaROc/" /><category term="development workflow" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="javascript" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Node.js" scheme="searchisko:content:tags" /><category term="react" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="s2i" scheme="searchisko:content:tags" /><category term="source-to-image" scheme="searchisko:content:tags" /><category term="web development" scheme="searchisko:content:tags" /><author><name>Lucas Holmquist</name></author><id>searchisko:content:id:jbossorg_blog-modern_web_applications_on_openshift_part_3_openshift_as_a_development_environment</id><updated>2019-01-17T13:00:37Z</updated><published>2019-01-17T13:00:37Z</published><content type="html">&lt;p&gt;Welcome back to the final part of this multipart series about deploying modern web applications on Red &lt;a href="http://openshift.com/"&gt;Hat OpenShift&lt;/a&gt;. In the &lt;a href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/"&gt;first post&lt;/a&gt;, we took a look at how to deploy a modern web application using the fewest commands.&lt;/p&gt; &lt;p&gt;In the &lt;a href="https://developers.redhat.com/blog/2018/10/23/modern-web-applications-on-openshift-part-2-using-chained-builds/"&gt;second part&lt;/a&gt;, we took a deeper look into how the new source-to-image (S2I) web app builder works and how to use it as part of a chained build.&lt;/p&gt; &lt;p&gt;This third and final part will take a look at how you can run your app&amp;#8217;s &amp;#8220;development workflow&amp;#8221; on OpenShift.&lt;span id="more-527607"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Development workflow&lt;/h2&gt; &lt;p&gt;As mentioned in the &lt;a href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/"&gt;first post&lt;/a&gt;, a common development workflow for modern web applications is to run a &amp;#8220;development server&amp;#8221; that watches your local files for changes. When a change occurs, the application&amp;#8217;s build is run and the browser is refreshed with your updated app.&lt;/p&gt; &lt;p&gt;Most of the modern frameworks have this &amp;#8220;development server&amp;#8221; built into their respective CLI tools.&lt;/p&gt; &lt;h3&gt;A local example&lt;/h3&gt; &lt;p&gt;Let&amp;#8217;s first start with running our application locally, so we can see how this workflow is supposed to work. We are going to continue with the &lt;a href="https://github.com/lholmquist/react-web-app"&gt;React example&lt;/a&gt; that we saw in the previous articles. Even though we are using React as an example here, the workflow concepts are very similar for all the other modern frameworks.&lt;/p&gt; &lt;p&gt;For this React example, to start the &amp;#8220;development server&amp;#8221; we run the following:&lt;/p&gt; &lt;pre&gt;$ npm run start &lt;/pre&gt; &lt;p&gt;We should see something like this in our terminal:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-dev-server-local-1.png"&gt;&lt;img class=" aligncenter wp-image-528457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-dev-server-local-1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-dev-server-local-1.png" alt="Starting the development server" width="572" height="253" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-dev-server-local-1.png 572w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-dev-server-local-1-300x133.png 300w" sizes="(max-width: 572px) 100vw, 572px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And our application should open in our default browser:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost.png"&gt;&lt;br /&gt; &lt;img class=" aligncenter wp-image-528467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost-1024x620.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost-1024x620.png" alt="Application running in a browser" width="640" height="388" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost-1024x620.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost-300x182.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost-768x465.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/react-localhost.png 1205w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Now, if we make a change to a file, we should see the application running in the browser refresh with the latest changes.&lt;/p&gt; &lt;p&gt;As I said before, this is a common workflow for local development, but how can we get this workflow onto OpenShift?&lt;/p&gt; &lt;h3&gt;Development server on OpenShift&lt;/h3&gt; &lt;p&gt;In the &lt;a href="https://developers.redhat.com/blog/2018/10/23/modern-web-applications-on-openshift-part-2-using-chained-builds/"&gt;previous article&lt;/a&gt;, we took a look at the run phase of the S2I image. We saw that the default way of serving our web app is with the &lt;code&gt;serve&lt;/code&gt; module.&lt;/p&gt; &lt;p&gt;However, if we &lt;a href="https://github.com/nodeshift/centos7-s2i-web-app/blob/master/s2i/run#L10"&gt;look closely at that run script&lt;/a&gt;, we can see that we can specify an environment variable, &lt;code&gt;$NPM_RUN&lt;/code&gt;, which gives us the ability to execute a custom command.&lt;/p&gt; &lt;p&gt;For example, using the &lt;code&gt;nodeshift&lt;/code&gt; module, the command to deploy our application might look something like this:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --deploy.env NPM_RUN="yarn start" --dockerImage=nodeshift/centos7-s2i-web-app &lt;/pre&gt; &lt;p&gt;&lt;em&gt;Note: The above example has been shortened to show an idea.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Here we are adding the &lt;code&gt;NPM_RUN&lt;/code&gt; environment variable to our deployment. This will tell our run phase to run &lt;code&gt;yarn start&lt;/code&gt;, which starts the React development server inside our OpenShift pod.&lt;/p&gt; &lt;p&gt;If you took a look at the log of the running pod, you might see something like this running:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server.png"&gt;&lt;img class=" aligncenter wp-image-553467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server-1024x550.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server-1024x550.png" alt="Log of the running pod" width="640" height="344" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server-1024x550.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server-300x161.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server-768x413.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/react-pod-dev-server.png 1381w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Of course, this doesn&amp;#8217;t really matter unless we can sync our local code with the code that is being watched on our remote cluster.&lt;/p&gt; &lt;h3&gt;Remote and local sync&lt;/h3&gt; &lt;p&gt;Luckily, we can use &lt;code&gt;nodeshift&lt;/code&gt; again to help us out. We can use the &lt;code&gt;watch&lt;/code&gt; command.&lt;/p&gt; &lt;p&gt;After we run the command to deploy our application&amp;#8217;s development server, we can then run this command:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift watch &lt;/pre&gt; &lt;p&gt;This will connect to the running pod we just created and sync our local files with our remote cluster, while also watching our local system for changes.&lt;/p&gt; &lt;p&gt;So if you were to update the &lt;code&gt;src/App.js&lt;/code&gt; file, that change will be detected and copied to the remote cluster, and the running development server will then refresh the browser.&lt;/p&gt; &lt;p&gt;For completeness, here are the full commands:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --strictSSL=false --dockerImage=nodeshift/centos7-s2i-web-app --build.env YARN_ENABLED=true --expose --deploy.env NPM_RUN="yarn start" --deploy.port 3000 $ npx nodeshift watch --strictSSL=false &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;watch&lt;/code&gt; command is an abstraction on top of the &lt;code&gt;oc rsync&lt;/code&gt; command. To learn more about how that works, &lt;a href="https://docs.okd.io/latest/dev_guide/copy_files_to_container.html" target="_blank" rel="noopener"&gt;check it out here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Even though the example we saw was using React, this technique also works with other frameworks. You just need to change the &lt;code&gt;NPM_RUN&lt;/code&gt; environment variable.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this 3 part series, we saw how to deploy modern web applications to OpenShift in a few ways.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/" target="_blank" rel="noopener"&gt;In part one,&lt;/a&gt; we saw how to get started quickly with the new Web App S2I Image.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2018/10/23/modern-web-applications-on-openshift-part-2-using-chained-builds/" target="_blank" rel="noopener"&gt;Part 2 dove a little deeper&lt;/a&gt; into how the S2I image worked and how to use chained builds.&lt;/p&gt; &lt;p&gt;This last part was a brief overview of how you can run a development server on OpenShift.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/books/deploying-openshift/"&gt;Deploying to OpenShift: a guide for impatient developers&lt;/a&gt; (free ebook)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/06/11/container-native-nodejs-istio-rhoar/" rel="bookmark"&gt;Building Container-Native Node.js Applications with Red Hat OpenShift Application Runtimes and Istio&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/15/debug-your-node-js-application-on-openshift-with-chrome-devtools/" rel="bookmark"&gt;How to Debug Your Node.js Application on OpenShift with Chrome DevTools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/04/16/zero-express-openshift-3-commands/" rel="bookmark"&gt;Zero to Express on OpenShift in Three Commands&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/03/12/rhoar-nodejs-annoucement/" rel="bookmark"&gt;Announcing: Node.js General Availability in Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/12/21/monitoring-node-js-applications-on-openshift-with-prometheus/" rel="bookmark"&gt;Monitoring Node.js Applications on OpenShift with Prometheus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Other articles on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;OpenShift and Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#38;linkname=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F17%2Fmodern-web-applications-on-openshift-part-3-openshift-as-a-development-environment%2F&amp;#038;title=Modern%20web%20applications%20on%20OpenShift%3A%20Part%203%20%E2%80%94%20Openshift%20as%20a%20development%20environment" data-a2a-url="https://developers.redhat.com/blog/2019/01/17/modern-web-applications-on-openshift-part-3-openshift-as-a-development-environment/" data-a2a-title="Modern web applications on OpenShift: Part 3 — Openshift as a development environment"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/17/modern-web-applications-on-openshift-part-3-openshift-as-a-development-environment/"&gt;Modern web applications on OpenShift: Part 3 &amp;#8212; Openshift as a development environment&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/siuhebeaROc" height="1" width="1" alt=""/&gt;</content><summary>Welcome back to the final part of this multipart series about deploying modern web applications on Red Hat OpenShift. In the first post, we took a look at how to deploy a modern web application using the fewest commands. In the second part, we took a deeper look into how the new source-to-image (S2I) web app builder works and how to use it as part of a chained build. This third and final part will...</summary><dc:creator>Lucas Holmquist</dc:creator><dc:date>2019-01-17T13:00:37Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/17/modern-web-applications-on-openshift-part-3-openshift-as-a-development-environment/</feedburner:origLink></entry><entry><title>How much faster is Java 11?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/B2kQ9o1WBPg/HowMuchFasterIsJava11.html" /><category term="benchmark" scheme="searchisko:content:tags" /><category term="feed_group_name_optaplanner" scheme="searchisko:content:tags" /><category term="feed_name_optaplanner" scheme="searchisko:content:tags" /><category term="production" scheme="searchisko:content:tags" /><author><name>rsynek</name></author><id>searchisko:content:id:jbossorg_blog-how_much_faster_is_java_11</id><updated>2019-01-18T17:26:10Z</updated><published>2019-01-17T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Java 11 was released some time ago, although the &lt;a href="https://www.baeldung.com/java-in-2018"&gt;majority of developers stay on Java 8&lt;/a&gt;. Let’s see which one of them is faster for &lt;a href="https://www.optaplanner.org/"&gt;OptaPlanner&lt;/a&gt;. The best way to find out is of course running OptaPlanner benchmarks. This article is a follow up on &lt;a href="https://www.optaplanner.org/blog/2014/03/20/HowMuchFasterIsJava8.html"&gt;our similar article for Java 8&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_benchmark_methodology"&gt;Benchmark methodology&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To run the benchmark we used:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A stable machine without any other computational demanding processes running and with &lt;code&gt;2 x Intel® Xeon® CPU E5-2609 0 @ 2.4 GHz (8 cores total)&lt;/code&gt; and &lt;code&gt;31.3 GiB&lt;/code&gt; RAM memory, running RHEL 6.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Both G1 and Parallel GC for both Java versions to compare the impact of garbage collection. Java executed with the parameters &lt;code&gt;-Xmx1536M -server -XX:+UseG1GC&lt;/code&gt; and &lt;code&gt;-Xmx1536M -server -XX:+UseParallelGC&lt;/code&gt; respectively.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Both Oracle Java 8:&lt;/p&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;java version "1.8.0_191" Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;and OpenJDK 11:&lt;/p&gt; &lt;/div&gt; &lt;div class="literalblock"&gt; &lt;div class="content"&gt; &lt;pre&gt;openjdk version "11.0.1" 2018-10-16 OpenJDK Runtime Environment 18.9 (build 11.0.1+13) OpenJDK 64-Bit Server VM 18.9 (build 11.0.1+13, mixed mode)&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;OptaPlanner &lt;code&gt;7.14.0.Final&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Solving a planning problem involves &lt;strong&gt;no IO&lt;/strong&gt; (except a few milliseconds during startup to load the input). &lt;strong&gt;A single CPU is completely saturated.&lt;/strong&gt; It constantly creates many short-lived objects, and the GC collects them afterwards.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Each run solves 11 planning problems with OptaPlanner. Each planning problem runs for 5 minutes and starts with a 30 second JVM warm up which is discarded.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The benchmarks measure the number of scores calculated per millisecond. Higher is better. Calculating a score for a proposed planning solution is non-trivial: it involves many calculations, including checking for conflicts between every entity and every other entity.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_executive_summary"&gt;Executive summary&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;With Java 11, the average improvement is &lt;strong&gt;16.1%&lt;/strong&gt; for G1 and &lt;strong&gt;4.5%&lt;/strong&gt; for Parallel GC. Although Parallel GC is oriented towards throughput, whereas G1 focuses rather on low-latency garbage collection, the significant improvement of G1 in Java 11 leads to a direct &lt;a href="#table3"&gt;comparison of these two garbage collection algorithms&lt;/a&gt;. For more information about difference between various GC algorithms, please see &lt;a href="https://dzone.com/articles/choosing-the-right-gc"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This shows that Parallel GC is still the preferred GC for OptaPlanner, as throughput is much more important for solving optimization problems with OptaPlanner than the latencies introduced by the GC.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_results"&gt;Results&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_java_8_vs_java_11"&gt;Java 8 vs. Java 11&lt;/h3&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="Java8VsJava11usingG1GC.svg" alt="Java8VsJava11usingG1GC"&gt; &lt;/img&gt; &lt;/div&gt; &lt;table id="table1" class="tableblock frame-all grid-all spread"&gt; &lt;caption class="title"&gt;Table 1. Score calculation count per second with G1 GC&lt;/caption&gt; &lt;colgroup&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3337%;"&gt; &lt;/col&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top" /&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Cloud balancing&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Machine reassignment&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Course scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Exam scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Nurse rostering&lt;sup&gt;.&lt;/sup&gt;&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Traveling Tournament&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;JDK&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;200c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;800c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B10&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c7&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c8&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s2&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s3&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;m1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;mh1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;nl14&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Java 8&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;38,074&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;34,870&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;113,490&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;20,398&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,296&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,840&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;7,003&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,437&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,385&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,021&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;812&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;OpenJDK 11&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;41,753&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;41,282&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;166,676&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;20,363&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,473&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,466&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;8,157&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,927&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,772&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,536&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;957&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Difference&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;9.7%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;18.4%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;46.9%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-0.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4.1%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;12.9%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;16.5%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;9.0%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;16.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;25.5%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;17.9%&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Average&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="11"&gt;&lt;p class="tableblock"&gt;&lt;strong&gt;16.1%&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/col&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Almost every data set improves on Java 11 over Java 8 using the G1 garbage collector. On average, there’s a 16% improvement just by switching to Java 11. A possible explanation for this improvement could be the &lt;a href="http://openjdk.java.net/jeps/307"&gt;JEP 307: Parallel Full GC for G1&lt;/a&gt;, introduced in Java 10.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="Java8VsJava11usingParallelGC.svg" alt="Java8VsJava11usingParallelGC"&gt; &lt;/img&gt; &lt;/div&gt; &lt;table class="tableblock frame-all grid-all spread"&gt; &lt;caption class="title"&gt;Table 2. Score calculation count per second with Parallel GC&lt;/caption&gt; &lt;colgroup&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3337%;"&gt; &lt;/col&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top" /&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Cloud balancing&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Machine reassignment&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Course scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Exam scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Nurse rostering&lt;sup&gt;.&lt;/sup&gt;&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Traveling Tournament&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;JDK&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;200c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;800c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B10&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c7&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c8&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s2&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s3&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;m1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;mh1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;nl14&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Java 8&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;54,990&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;52,514&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;122,611&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;13,382&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,821&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,880&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;8,775&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;6,170&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3,234&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,682&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;880&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;OpenJDK 11&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;54,316&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;50,120&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;140,816&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;11,129&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,927&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;6,071&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;8,996&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;6,383&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3,336&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3,087&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;1,125&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Difference&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-1.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-4.6%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;14.8%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-16.8%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2.5%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3.5%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;15.1%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;27.8%&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Average&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="11"&gt;&lt;p class="tableblock"&gt;&lt;strong&gt;4.5%&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/col&gt; &lt;div class="paragraph"&gt; &lt;p&gt;With the Parallel Garbage Collector, the results are less definite than G1. There is an improvement for some data sets, while others remain intact or show even a performance drop. However, on average, the Java 11 performs over 4% better.&lt;/p&gt; &lt;/div&gt; &lt;/col&gt; &lt;div class="sect2"&gt; &lt;h3 id="_parallel_gc_vs_g1_gc_on_java_11"&gt;Parallel GC vs. G1 GC on Java 11&lt;/h3&gt; &lt;table id="table3" class="tableblock frame-all grid-all spread"&gt; &lt;caption class="title"&gt;Table 3. Comparison of score calculation count per second on Java 11 with Parallel GC and G1 GC being used&lt;/caption&gt; &lt;colgroup&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3333%;"&gt; &lt;col style="width: 8.3337%;"&gt; &lt;/col&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top" /&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Cloud balancing&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Machine reassignment&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Course scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Exam scheduling&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="2"&gt;&lt;p class="tableblock"&gt;Nurse rostering&lt;sup&gt;.&lt;/sup&gt;&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Traveling Tournament&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Java 11&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;200c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;800c&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;B10&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c7&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;c8&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s2&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;s3&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;m1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;mh1&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-top"&gt;&lt;p class="tableblock"&gt;nl14&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;OpenJDK 11 Parallel GC&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;54,316&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;50,120&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;140,816&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;11,129&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,927&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;6,071&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;8,996&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;6,383&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3,336&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;3,087&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;1,125&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;OpenJDK 11 G1 GC&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;41,753&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;41,282&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;166,676&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;20,363&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;4,473&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,466&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;8,157&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;5,927&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,772&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;2,536&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;957&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Difference&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-23.1%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-17.6%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;18.4%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;83.0%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-9.2%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-10.0%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-9.3%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-7.1%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-16.9%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-17.8%&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-right valign-top"&gt;&lt;p class="tableblock"&gt;-14.9%&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td class="tableblock halign-left valign-top"&gt;&lt;p class="tableblock"&gt;Average&lt;/p&gt;&lt;/td&gt; &lt;td class="tableblock halign-center valign-middle" colspan="11"&gt;&lt;p class="tableblock"&gt;&lt;strong&gt;-2.3%&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/col&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Although G1 GC shows a clear improvement from Java 8, compared to Parallel GC it’s less beneficial GC strategy for OptaPlanner on the majority of the data sets. The only exception is Machine Reassignment, which shows that the G1 OptaPlanner is able to compute score calculation 83% faster. This applies to Java 8 too, as shown in &lt;a href="#table1"&gt;Score calculation count per second with G1 GC&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/col&gt; &lt;/col&gt; &lt;/col&gt; &lt;div class="sect1"&gt; &lt;h2 id="_conclusion"&gt;Conclusion&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Java 11 brings additional improvements, which vary across different &lt;a href="https://www.optaplanner.org/"&gt;OptaPlanner&lt;/a&gt; examples and data sets. On average, it is 4.5% faster when using Parallel GC and 16.1% faster with G1 GC. Despite the significant improvement for G1 GC, Parallel GC is still faster for most data sets in this benchmark.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/div&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/div&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/col&gt;&lt;/colgroup&gt;&lt;/table&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/B2kQ9o1WBPg" height="1" width="1" alt=""/&gt;</content><summary>Java 11 was released some time ago, although the majority of developers stay on Java 8. Let’s see which one of them is faster for OptaPlanner. The best way to find out is of course running OptaPlanner benchmarks. This article is a follow up on our similar article for Java 8. Benchmark methodology To run the benchmark we used: A stable machine without any other computational demanding processes run...</summary><dc:creator>rsynek</dc:creator><dc:date>2019-01-17T00:00:00Z</dc:date><feedburner:origLink>https://www.optaplanner.org/blog/2019/01/17/HowMuchFasterIsJava11.html</feedburner:origLink></entry><entry><title>Leveraging OpenShift or Kubernetes for automated performance tests (part 3)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MFp67gKpwPc/" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="jenkins" scheme="searchisko:content:tags" /><category term="JMeter" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><category term="performance testing" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="test automation" scheme="searchisko:content:tags" /><author><name>Frédéric Giloux</name></author><id>searchisko:content:id:jbossorg_blog-leveraging_openshift_or_kubernetes_for_automated_performance_tests_part_3</id><updated>2019-01-16T13:00:08Z</updated><published>2019-01-16T13:00:08Z</published><content type="html">&lt;p&gt;This is the third of a series of three articles based on a session I held at EMEA Red Hat Tech Exchange. In the &lt;a href="https://developers.redhat.com/blog/2018/11/22/automated-performance-testing-kubernetes-openshift/"&gt;first article&lt;/a&gt;, I presented the rationale and approach for leveraging &lt;a href="https://www.openshift.com"&gt;Red Hat OpenShift&lt;/a&gt; or &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; for automated performance testing, and I gave an overview of the setup. In the &lt;a href="https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/"&gt;second article&lt;/a&gt;, we looked at building an observability stack. In this third part, we will see how the execution of the performance tests can be automated and related metrics gathered.&lt;/p&gt; &lt;p&gt;An example of what is described in this article is available in my &lt;a href="https://github.com/fgiloux/auto-perf-test/"&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-552337"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Overview of the setup&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6.png"&gt;&lt;img class="aligncenter wp-image-533387 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-1024x433.png" alt="Overview" width="640" height="271" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-1024x433.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6-768x324.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/11/img_5bdc69ff84eb6.png 1250w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2 id="_test_automation"&gt;Test automation&lt;/h2&gt; &lt;h3 id="_test_suite"&gt;Test plan&lt;/h3&gt; &lt;p&gt;As we saw in the first article, there are several aspects that need to be taken into consideration for building a test plan that is representative of production scenarios and can easily be reused. Let&amp;#8217;s go through the examples provided in my &lt;a href="https://github.com/fgiloux/auto-perf-test/tree/master/jmeter/examples"&gt;GitHub repository&lt;/a&gt; and see how we can approach them.&lt;/p&gt; &lt;p&gt;My first advice was to use the JMeter GUI (I used JMeter 4 for this article) and its standard components for quick experimentation and as a feedback loop during the design phase. Here is &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/examples/jms-declarative.jmx"&gt;an example&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;When we are happy with the design, we can move on to writing custom components in Groovy (a dynamic language for the Java platform that&amp;#8217;s also compatible with Java syntax), which provides more power and flexibility but also requires more effort. See examples &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/examples/jms-code.jmx"&gt;here&lt;/a&gt;. Running the JMeter GUI is as simple as &lt;a href="https://jmeter.apache.org/download_jmeter.cgi"&gt;downloading the archive&lt;/a&gt;, extracting it, and calling &lt;code&gt;./bin/jmeter&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s go through the JMS test suite using JSR 223 samplers (Groovy).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;General structure&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The test plan example is composed of the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Thread groups containing controllers/samplers, timers, and data sets&lt;/li&gt; &lt;li&gt;User-defined variables&lt;/li&gt; &lt;li&gt;Listeners: a data writer and a back-end listener&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Assertions are not used here.&lt;/p&gt; &lt;p&gt;Per the &lt;a href="https://jmeter.apache.org/usermanual/test_plan.html"&gt;JMeter documentation&lt;/a&gt;, a thread group is the starting point of any JMeter test plan. All the elements of a test plan must be defined under the thread group. Setup and teardown thread groups are also used: they are special forms of thread groups used to perform necessary actions before and after, respectively, execution of regular thread groups. We use them for loading a message template and creating a connection to the broker.&lt;/p&gt; &lt;p&gt;We make use of global user-defined variables for allocating connection string parameters or for defining flags when we want the code to be processed only once inside a thread.&lt;/p&gt; &lt;p&gt;In regard to listeners, data writers and back-end listeners provide access to the information collected by JMeter about the test cases and allow it to be recorded in files (see &lt;a href="https://jmeter.apache.org/usermanual/component_reference.html#Simple_Data_Writer"&gt;Simple Data Writer&lt;/a&gt;) or InfluxDB (see &lt;a href="https://jmeter.apache.org/usermanual/component_reference.html#Backend_Listener"&gt;Backend Listener&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Configuration externalization&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;There are two ways to pass properties to a JMeter test plan. The first is to define them in &lt;code&gt;./bin/user.properties&lt;/code&gt;. The second is to pass them at startup using &lt;code&gt;-J&lt;/code&gt;, for example, &lt;code&gt;-JBROKER&lt;/code&gt;. We will see how this latter form can easily be leveraged when JMeter runs in a &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;container&lt;/a&gt; on &lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt; with a simple startup script passing injected environment variables as properties.&lt;/p&gt; &lt;p&gt;Properties can then be used among others in user-defined variables. This is what we are using, for instance, for the AMQP connection string:&lt;/p&gt; &lt;pre&gt;${__P(BROKER,messaging-perftest.apps.sandbox.com)}amqps://${__P(BROKER,messaging-perftest.apps.sandbox.com)}:${__P(PORT,443)}?transport.trustStoreLocation=${__P(JKS_LOCATION,/myrepolocation/auto-perf-test/camel-amq-fakeapp/src/main/resources/amqp-certs/amqp.jks)}&amp;#38;transport.trustStorePassword=${__P(JKS_PWD,redhat)}&amp;#38;transport.verifyHost=false&lt;/pre&gt; &lt;p&gt;With this example, if no parameter named &lt;code&gt;BROKER&lt;/code&gt; is passed, the default value, &lt;code&gt;messaging-perftest.apps.sandbox.com&lt;/code&gt;, applies. The variable can then be retrieved in Groovy with &lt;code&gt;vars.get("connection_string")&lt;/code&gt; and the property with &lt;code&gt;props.get("PAIN_TEMPLATE_LOCATION")&lt;/code&gt;. In a declarative component, &lt;code&gt;${connection_string}&lt;/code&gt; (confer the JMS Purge element in the example provided in my GitHub repository) can be used.&lt;/p&gt; &lt;p&gt;The same strategy applies to certificate configuration where the Java Key Store (JKS) location and password are passed as properties. The JKS itself is injected into the container file system by mounting a secret containing it.&lt;/p&gt; &lt;p&gt;Furthermore, test parameters like the number of messages, the injection rate, the duration, and so on can be injected through properties so that different test cases can be run one after the other without human intervention or replicating the test code.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Data sets&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;As stated in part 1 of this series, we should use data sets that are representative of the data in production. It should be possible to reuse them between runs. JMeter provides a convenient way for that through &lt;a href="https://jmeter.apache.org/usermanual/component_reference.html#CSV_Data_Set_Config"&gt;CSV Data Set Config&lt;/a&gt;. It is indeed possible to provide a CSV file with headers like &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/examples/pain_samples.csv"&gt;this one&lt;/a&gt;. Variables are created using the header names and populated with the raw values. The next line of the CSV file is used by the next iteration. This, combined with &lt;a href="http://groovy-lang.org/templating.html"&gt;Groovy templating capabilities&lt;/a&gt;, is a strong tool for creating workloads that reflect the diversity of production data and the occurrences of different patterns. A simple &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/examples/pain_template.xml"&gt;XML template&lt;/a&gt; is used as part of the demo.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Additional libraries&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;It is often required to provide libraries to JMeter so that the test plan can send messages to a broker or integrate with external systems like Jaeger. Therefore, the desired libraries just need to be added to the JMeter &lt;code&gt;lib&lt;/code&gt; directory.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Cleansing first&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We saw previously that a clean environment is required before the tests can be run. Therefore, the test plan purges the queues. Using thread groups with different offsets (startup delay), it is possible to let the purge action finish before messages get sent to the broker. This was configured in the test plan using the JMS point-to-point component.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Injection pattern&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In the first part, we saw that latency and, to some extent, throughput get impacted by the way messages get injected. JMeter allows re-creating complex injection patterns using various timer components. In the demo, we have configured a constant throughput timer that targets sending 600 messages per minute. This is applied to all active threads in the current thread group, but JMeter allows other options and provides &lt;a href="https://jmeter.apache.org/usermanual/component_reference.html#timers"&gt;various timers&lt;/a&gt; out of the box. If none of them are suitable, it is also possible to code one in Groovy.&lt;/p&gt; &lt;h3 id="_extending_observability"&gt;Extending observability&lt;/h3&gt; &lt;p&gt;Measurement points matter for getting the real story and having test results that reflect what is expected from the application in production. With brokered messages, the enqueued time spent by messages is often more important than the time required by the application for processing.&lt;/p&gt; &lt;p&gt;To get values close enough to the end-to-end elapsed time, it is possible to use JMS timestamps. This is what has been done in the demo. The sender sets the time when the message is ready to be sent, and the receiver subtracts it from the JMS timestamp set by the message publisher inside the application. It is still an approximation, but it&amp;#8217;s usually not off by more than a few milliseconds. This allows moving away from the requirement of &amp;#8220;instantaneous&amp;#8221; reads.&lt;/p&gt; &lt;p&gt;All the results gathered by JMeter can be saved in a file. This is what is done by the simple data writer in the demo. JMeter is also able to export results to InfluxDB. A backend listener does that out of the box (as in the demo). It is again possible to use a Groovy script for this purpose, which would provide additional flexibility in terms of data selection.&lt;/p&gt; &lt;p&gt;The JMeter data in InfluxDB can be retrieved and displayed through Grafana. This is what is done in the dashboard presented in the second part of this series. Here are the JMeter graphs.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana.png"&gt;&lt;img class=" aligncenter wp-image-552397 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana-1024x133.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana-1024x133.png" alt="JMeter graphs" width="640" height="83" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana-1024x133.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana-300x39.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jmeter-grafana-768x100.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In a similar way, the tracing span we saw in the previous article can be extended to include a JMeter sender and receiver. For the demo, the OpenTracing and Jaeger libraries have been added to the &lt;code&gt;lib&lt;/code&gt; directory. A tracer is created per thread in the setUp Thread group and added to the properties. It can then be retrieved in the sender code, where a &lt;code&gt;TracingMessageProducer&lt;/code&gt; is used instead of the standard JMS producer. Similarly, a &lt;code&gt;TracingMessageConsumer&lt;/code&gt; is used with the tracer instead of the standard JMS component in the consumer code. This produces the result in Jaeger that we already saw in the previous article.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger.png"&gt;&lt;img class=" aligncenter wp-image-552427 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger-1024x435.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger-1024x435.png" alt="Result in Jaeger" width="640" height="272" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger-1024x435.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger-300x127.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jaeger-768x326.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3 id="_containerisation"&gt;Containerization&lt;/h3&gt; &lt;p&gt;The first step for running JMeter in a container is to create an image with it and the libraries we have added. This is done through &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/container/Dockerfile"&gt;this Dockerfile&lt;/a&gt; in the demo.&lt;/p&gt; &lt;p&gt;Another aspect is that the parameters need to be provided to the JMeter process at startup. The &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/container/scripts/run.sh"&gt;startup script&lt;/a&gt; does that. The logic is based on the following convention: every environment variable prefixed with &lt;code&gt;J_&lt;/code&gt; gets passed to the JMeter process.&lt;/p&gt; &lt;p&gt;The script also runs the test plans that have been provided in a specific directory. This allows us to mount a &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/openshift/apt-jmx-cm.yaml"&gt;configMap&lt;/a&gt; into the container file system and have the test plans provided by it with the required data sets and templates executed without the need to re-create a container image. In a similar way, certificates used to communicate with the broker are injected through secrets and mounted into the container file system. The test results are stored on a persistent volume, which makes it possible to have the same directory mounted into the Jenkins container.&lt;/p&gt; &lt;p&gt;Finally, the script makes a REST call if a URL has been provided to notify Jenkins (it would work with other CI tools as well) that the execution of the test plan(s) has completed.&lt;/p&gt; &lt;p&gt;The last point is that a sidecar container is used for taking over the communication with the Jaeger server. This can be seen in the &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/openshift/apt-jmeter-job-persistent-tm.yaml"&gt;deployment configuration&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Detailed instructions on how to build the container image and run it on OpenShift are available in &lt;a href="https://github.com/fgiloux/auto-perf-test/tree/master/jmeter"&gt;my GitHub repository&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="_orchestration"&gt;Orchestration&lt;/h2&gt; &lt;p&gt;The last missing bit is how can we automate the complete chain: from re-creating a clean environment with the latest code version to triggering the test run, asserting the results, tagging the code, performing configuration, creating container images and eventually promoting them to the next environment?&lt;/p&gt; &lt;h3 id="_pipeline"&gt;Pipeline&lt;/h3&gt; &lt;p&gt;Jenkins is the tool of choice for &lt;a href="https://developers.redhat.com/blog/category/ci-cd/"&gt;CI/CD&lt;/a&gt; on &lt;a href="https://developers.redhat.com/blog/category/kubernetes/"&gt;Kubernetes&lt;/a&gt; and it is shipped with OpenShift. &lt;a href="https://jenkins.io/doc/book/pipeline/"&gt;Pipelines&lt;/a&gt; are the recommended approach for automating these processes. When you start using Jenkins and pipelines for more and more components, you will see lots of similarities between them. For reusability, it is then best to use &lt;a href="https://jenkins.io/doc/book/pipeline/shared-libraries/"&gt;shared libraries&lt;/a&gt;. This was not done in our demo, but it is a simple task left to the reader.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s look now at the steps of the &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jenkins/pipelines/Jenkinsfile"&gt;demo Pipeline&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Trigger&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Ideally,  performance tests would run after every commit to the trunk. They should indeed be part of non-regression testing. There are plugins for integrating with various version control systems (VCS) like &lt;a href="https://wiki.jenkins.io/display/JENKINS/GitHub+Integration+Plugin"&gt;this one&lt;/a&gt;, which enable just that. It may, however, not be possible due to high resource requirements or the length of the tests. In that case, on-schedule runs are the next best thing. This can be done with the following single line in our Jenkins file, which will execute the pipeline once a day with automated distribution (you don’t want all your tests to be triggered at the exact same time).&lt;/p&gt; &lt;pre&gt;cron('H H * * *')&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Interacting with the OpenShift cluster&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The necessary plugins for interacting with OpenShift come configured out of the box with the default Jenkins container. Lots of operations are then made easy by the &lt;a href="https://github.com/openshift/jenkins-client-plugin"&gt;OpenShift Jenkins pipeline plugin&lt;/a&gt;, for instance, displaying the name of the current project:&lt;/p&gt; &lt;pre&gt;openshift.withCluster() { openshift.withProject() { echo "Using project: ${openshift.project()}" } }&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Clean sheet&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;When we run our test plan, we want to make sure that we are testing the desired code version and that there is no impact due to leftovers from previous test runs. Therefore, &amp;#8220;delete and re-create&amp;#8221; is the best approach. This can be done at the project/namespace level or labels can be used for a fine-grained approach. It is easy to apply a common label to all the objects deployed as part of the test run. They can then be retrieved and deleted using the following lines, where &lt;code&gt;testPlanName&lt;/code&gt; is specific to the pipeline or pipeline run if we want to allow parallel runs.&lt;/p&gt; &lt;pre&gt;if (openshift.selector("all", [ "testplan" : testPlanName ]).exists()) { openshift.selector("all", [ "testplan" : testPlanName ]).delete() } // all not being all if (openshift.selector("secrets", [ "testplan" : testPlanName ]).exists()) { openshift.selector("secrets", [ "testplan" : testPlanName ]).delete() } if (openshift.selector("configMaps", [ "testplan" : testPlanName ]).exists()) { openshift.selector("configMaps", [ "testplan" : testPlanName ]).delete() }&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Provisioning&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Templates may be used for creating the required objects:&lt;/p&gt; &lt;pre&gt;openshift.withCluster() { openshift.withProject() { // "template" is the name of the template loaded in OpenShift openshift.newApp(template) } }&lt;/pre&gt; &lt;p&gt;Or single objects can also be created:&lt;/p&gt; &lt;pre&gt;def testPlanPath = 'https://raw.githubusercontent.com/fgiloux/auto-perf-test/master/jmeter/openshift/apt-jmx-cm.yaml' def testPlanCm = openshift.create(testPlanPath).object() // Applying label makes it is easy to recognise for cleansing testPlanCm.metadata.labels['testplan'] = testPlanName openshift.apply(testPlanCm)&lt;/pre&gt; &lt;p&gt;However, in real life you may want to have the complete configuration stored in a VCS, checked out, and created by the build pipeline from the cloned repository (same code as above executed in a loop over the config files available in a directory).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Building the application image&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For this, there are two schools of thought. The simplest approach is to have the build done in OpenShift with S2I. In that case, you would just start the build (potentially passing the repo branch/tag as a parameter) using a build configuration created during the environment provisioning, and OpenShift does the rest:&lt;/p&gt; &lt;pre&gt;def builds = openshift.selector("bc", 'camel-amq-fakeapp-s2i').startBuild("--wait=true")&lt;/pre&gt; &lt;p&gt;Another approach is to use a Maven slave (running in a container on OpenShift) to build the artifacts, push them to an artifact repository (like Nexus or Artifactory), have them scanned through SonarQube, and released (version number updated) and used for building the final container image with the source code, image, and artifacts similarly tagged. However, describing this goes beyond the scope of this article.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Rolling out the application&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Now that the image has been created, we can run the application in our test environment and wait until it has been started before the tests are launched:&lt;/p&gt; &lt;pre&gt;def dc = openshift.selector("dc", 'camel-amq-fakeapp').rollout() timeout(5) { openshift.selector("dc", 'camel-amq-fakeapp').related('pods').untilEach(1) { return (it.object().status.phase == "Running") }&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Test plan execution&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We are now far enough along that the tests can be run. We may first want to register a &lt;a href="https://wiki.jenkins.io/display/JENKINS/Webhook+Step+Plugin"&gt;webhook&lt;/a&gt;, which is passed to the script running JMeter that we saw earlier:&lt;/p&gt; &lt;pre&gt;def hook = registerWebhook() def callbackUrl = hook.getURL()&lt;/pre&gt; &lt;p&gt;The next step is to run JMeter (best as a &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jmeter/openshift/apt-jmeter-job-tm.yaml"&gt;job&lt;/a&gt;) with the required parameters, where &lt;code&gt;BUILD_NUMBER&lt;/code&gt; is automatically generated by Jenkins and identifies the run:&lt;/p&gt; &lt;pre&gt;def models = openshift.process("apt-jmeter-job", "-p", "JMX_CONFIGMAP=${testPlanName}","-p","RESULT_SUB_DIR=${JOB_NAME}/${BUILD_NUMBER}","-p","CALLBACK_URL=${callbackUrl}")&lt;/pre&gt; &lt;p&gt;The Jenkins plugin lets us easily manipulate the object definition and, for instance, add a label to our job:&lt;/p&gt; &lt;pre&gt;for ( o in models ) { o.metadata.labels['testplan'] = testPlanName }&lt;/pre&gt; &lt;p&gt;The result can be applied to OpenShift:&lt;/p&gt; &lt;pre&gt;def created = openshift.create(models)&lt;/pre&gt; &lt;p&gt;At this point, the JMeter container is executing the test plan. We can wait until it has finished:&lt;/p&gt; &lt;pre&gt;timeout(10) { print "Waiting for tests to complete..." waitForWebhook hook }&lt;/pre&gt; &lt;p&gt;As we saw earlier, the test results are available on a shared drive mounted by Jenkins, so we can get them now processed by the Jenkins &lt;a href="https://wiki.jenkins.io/display/JENKINS/Performance+Plugin"&gt;performance plugin&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;perfReport sourceDataFiles: "/opt/performances/${JOB_NAME}/${BUILD_NUMBER}/*.jtl", compareBuildPrevious: true, modePerformancePerTestCase: true, modeOfThreshold: true, relativeFailedThresholdPositive: 50, relativeUnstableThresholdNegative: 40, relativeUnstableThresholdPositive: 40 // Job delete required due to the jaeger-agent sidecar not terminating with JMeter openshift.selector('job', ['testplan': testPlanName]).delete()&lt;/pre&gt; &lt;p&gt;This plugin provides a few graphs that give a quick overview of how the tests performed.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-overview.png"&gt;&lt;img class=" aligncenter wp-image-552467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-overview.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-overview.png" alt="Graphs that show performance information" width="502" height="740" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-overview.png 502w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-overview-204x300.png 204w" sizes="(max-width: 502px) 100vw, 502px" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;img class=" aligncenter wp-image-552477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-responsetime.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-responsetime.png" alt="" width="898" height="552" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-responsetime.png 898w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-responsetime-300x184.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/jenkins-jmeter-responsetime-768x472.png 768w" sizes="(max-width: 898px) 100vw, 898px" /&gt;&lt;/p&gt; &lt;p&gt;More importantly, the plugin provides the possibility of conditioning the pipeline result and next stages (pass or fail) on thresholds or deviations of previous runs.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tagging&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Finally, we may want to tag our image according to the outcome:&lt;/p&gt; &lt;pre&gt;openshift.tag("camel-amq-fakeapp:latest", "camel-amq-fakeapp:staging")&lt;/pre&gt; &lt;h3&gt;Image extension&lt;/h3&gt; &lt;p&gt;As we have seen going through the pipeline we may use additional plugins. In a disconnected environment, it is required to add them to the Jenkins image. In OpenShift, this is straightforward through the &lt;a href="https://docs.openshift.com/container-platform/3.10/using_images/other_images/jenkins.html#jenkins-as-s2i-builder"&gt;S2I process&lt;/a&gt;. The standard Jenkins template has also been amended to have the Jenkins container mount the persistent volume with the test result. This is available &lt;a href="https://github.com/fgiloux/auto-perf-test/blob/master/jenkins/openshift/perftest-jenkins-persistent-tm.yaml"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Whew; this was quite a long article! Congratulations to the readers who made it until the end. My last sentence is for saying thanks to my colleague Shrish Srivastava, who helped me with Prometheus and Grafana.&lt;/p&gt; &lt;h2&gt;All articles in Leveraging OpenShift or Kubernetes for automated performance test&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/22/automated-performance-testing-kubernetes-openshift/"&gt;Part 1: Rationale and approach&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/01/03/leveraging-openshift-or-kubernetes-for-automated-performance-tests-part-2/"&gt;Part 2: Building an observability stack&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: Automating tests and metrics gathering (this article)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#38;linkname=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F16%2Fopenshift-kubernetes-automated-performance-tests-part-3%2F&amp;#038;title=Leveraging%20OpenShift%20or%20Kubernetes%20for%20automated%20performance%20tests%20%28part%203%29" data-a2a-url="https://developers.redhat.com/blog/2019/01/16/openshift-kubernetes-automated-performance-tests-part-3/" data-a2a-title="Leveraging OpenShift or Kubernetes for automated performance tests (part 3)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/16/openshift-kubernetes-automated-performance-tests-part-3/"&gt;Leveraging OpenShift or Kubernetes for automated performance tests (part 3)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MFp67gKpwPc" height="1" width="1" alt=""/&gt;</content><summary>This is the third of a series of three articles based on a session I held at EMEA Red Hat Tech Exchange. In the first article, I presented the rationale and approach for leveraging Red Hat OpenShift or Kubernetes for automated performance testing, and I gave an overview of the setup. In the second article, we looked at building an observability stack. In this third part, we will see how the execut...</summary><dc:creator>Frédéric Giloux</dc:creator><dc:date>2019-01-16T13:00:08Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/16/openshift-kubernetes-automated-performance-tests-part-3/</feedburner:origLink></entry><entry><title>Podman: Managing pods and containers in a local container runtime</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/SZB7t9TN_Oc/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Podman" scheme="searchisko:content:tags" /><category term="pods" scheme="searchisko:content:tags" /><category term="Red Hat Enterprise Linux" scheme="searchisko:content:tags" /><author><name>Brent Baude</name></author><id>searchisko:content:id:jbossorg_blog-podman_managing_pods_and_containers_in_a_local_container_runtime</id><updated>2019-01-15T13:00:36Z</updated><published>2019-01-15T13:00:36Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;People associate running pods with &lt;/span&gt;&lt;a href="https://kubernetes.io/"&gt;&lt;span style="font-weight: 400;"&gt;Kubernetes&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. And when they run containers in their development runtimes, they do not even think about the role pods could play—even in a localized runtime.  Most people coming from the Docker world of running single containers do not envision the concept of running pods. There are several good reasons to consider using pods locally, other than using pods to naturally group your containers.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;For example, suppose you have multiple containers that require the use of a MariaDB container.  But you would prefer to not bind that database to a routable network; either in your bridge or further.  Using a pod, you could bind to the &lt;code&gt;localhost&lt;/code&gt; address of the pod and all containers in that pod will be able to connect to it because of the shared network name space.&lt;/span&gt;&lt;span id="more-553577"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Podman Pods: what you need to know&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The &lt;/span&gt;&lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/"&gt;&lt;span style="font-weight: 400;"&gt;Pod&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; concept was introduced by &lt;/span&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;&lt;span style="font-weight: 400;"&gt;Kubernetes&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;.  Podman pods are similar to the Kubernetes &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;definition. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture.png"&gt;&lt;img class=" aligncenter wp-image-554097 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture.png" alt="Podman architecture: containers in a pod" width="859" height="518" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture.png 859w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture-300x181.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/01/podman-pod-architecture-768x463.png 768w" sizes="(max-width: 859px) 100vw, 859px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Every Podman pod includes an &amp;#8220;infra&amp;#8221; container.   This container does nothing, but go to sleep. Its purpose is to hold the namespaces associated with the pod and allow podman to connect other containers to the pod.  This allows you to start and stop containers within the POD and the pod will stay running, where as if the primary container controlled the pod, this would not be possible. The default infra container is based on the &lt;code&gt;k8s.gcr.io/pause&lt;/code&gt; image,  Unless you explicitly say otherwise, all pods will have container based on the default image. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Most of the attributes that make up the Pod are actually assigned to the &amp;#8220;infra&amp;#8221; container.  Port bindings, cgroup-parent values, and kernel namespaces are all assigned to the “infra” container. This is critical to understand, because once the pod is created these attributes are assigned to the &amp;#8220;infra&amp;#8221; container and cannot be changed. For example, if you create a pod and then later decide you want to add a container that binds new ports, Podman will not be able to do this.  You would need to recreate the pod with the additional port bindings before adding the new container.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;In the above diagram, notice the box above each container, conmon, this is the container monitor.  It is a small C Program that’s job is to watch the primary process of the container, and if the container dies, save the exit code.  It also holds open the tty of the container, so that it can be attached to later. This is what allows podman to run in detached mode (backgrounded), so podman can exit but conmon continues to run.  Each container has its own instance of conmon.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;The CLI: podman pod&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We expose most of the interaction with pods through the &lt;code&gt;podman pod&lt;/code&gt; commands.  Among other actions, you can use &lt;code&gt;podman pod&lt;/code&gt; to create, delete, query, and inspect pods.  You can see all the pod related commands by running &lt;code&gt;podman pod&lt;/code&gt; without any arguments.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;NAME:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   podman pod - Manage container pods.&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;Pods are a group of one or more containers sharing the same network, pid and ipc namespaces.&lt;/span&gt; &lt;span style="font-weight: 400;"&gt; USAGE:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   podman pod command [command options] [arguments...]&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;COMMANDS:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;create    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Create a new empty pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;exists    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Check if a pod exists in local storage&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;inspect   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;displays a pod configuration&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;kill      &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Send the specified signal or SIGKILL to containers in pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;pause     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Pause one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;ps, ls, list  List pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;restart   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Restart one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;rm        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Remove one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;start     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Start one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;stats     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Display percentage of CPU, memory, network I/O, block I/O and PIDs for containers in one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;stop      &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Stop one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;top       &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Display the running processes of containers in a pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;unpause   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Unpause one or more pods&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;OPTIONS:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --help, -h  show help&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Create a pod&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The traditional way to create a pod with Podman is using the &lt;code&gt;podman pod create&lt;/code&gt; command.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod create --help&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;NAME:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   podman pod create - Create a new empty pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;USAGE:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   podman pod create [command options] [arguments...]&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;DESCRIPTION:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   Creates a new empty pod. The pod ID is then printed to stdout. You can then start it at any time with the podman pod start &amp;#60;pod_id&amp;#62; command. The pod will be created with the initial state 'created'.&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;OPTIONS:&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --cgroup-parent value  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Set parent cgroup for the pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --infra                &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Create an infra container associated with the pod to share namespaces with&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --infra-command value  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;The command to run on the infra container when the pod is started (default: "/pause")&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --infra-image value    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;The image of the infra container to associate with the pod (default: "k8s.gcr.io/pause:3.1")&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --label value, -l value&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Set metadata on pod (default [])&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --label-file value     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Read in a line delimited file of labels (default [])&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --name value, -n value &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Assign a name to the pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --pod-id-file value    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Write the pod ID to the file&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --publish value, -p value  Publish a container's port, or a range of ports, to the host (default [])&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;   --share value          &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;A comma delimited list of kernel namespaces the pod will share (default: "cgroup,ipc,net,uts")&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;In its most basic context, you can simply issue &lt;code&gt;podman pod create&lt;/code&gt; and Podman will create a pod without extra attributes.  A random name will also be assigned to the pod.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod create&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;9e0a57248aedc453e7b466d73ef769c99e35d265d97f6fa287442083246f3762&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We can list the pods using the &lt;code&gt;podman pod list&lt;/code&gt; command:&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod list&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS   INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;9e0a57248aed   youthful_jones  Running 5 seconds ago   1 &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;6074ffd22b93&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Note that the container has a single container in it.  The container is the &amp;#8220;infra&amp;#8221; command. We can further observe this using the &lt;code&gt;podman ps&lt;/code&gt; command by passing the command line switch *&amp;#8211;pod*.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman ps -a --pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND  CREATED  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS    &lt;/span&gt; &lt;span style="font-weight: 400;"&gt;PORTS  NAMES         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;6074ffd22b93  k8s.gcr.io/pause:3.1  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3 minutes ago  Up 3 minutes ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;9e0a57248aed-infra  9e0a57248aed&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Here we can see that the pod ID from &lt;code&gt;podman ps&lt;/code&gt; matches the pod id in &lt;code&gt;podman pod list&lt;/code&gt;.  And the container image is the same as the default &amp;#8220;infra&amp;#8221; container image.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Add a container to a pod&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You can add a container to a pod using the *&amp;#8211;pod* option in the &lt;code&gt;podman create&lt;/code&gt; and &lt;code&gt;podman run&lt;/code&gt; commands.  For example, here we add a container running **top** to the newly created *youthful_jones* pod. Notice the use of *&amp;#8211;pod*.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman run -dt --pod youthful_jones docker.io/library/alpine:latest top&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;0f62e6dcdfdbf3921a7d73353582fa56a545502c89f0dfcb8736ce7be61c9271&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;And now two containers exist in our pod.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod ps&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS   INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;9e0a57248aed   youthful_jones  Running 7 minutes ago   2 &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;6074ffd22b93&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Looking at the list of containers, we also see each container and their respective pod assignment.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman ps -a --pod&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE               &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND  CREATED   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS  NAMES          &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;0f62e6dcdfdb  docker.io/library/alpine:latest  top &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;14 seconds ago  Up 14 seconds ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;awesome_archimedes  9e0a57248aed&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;6074ffd22b93  k8s.gcr.io/pause:3.1                  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;7 minutes ago   Up 7 minutes ago      &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;9e0a57248aed-infra  9e0a57248aed&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Shortcut to create pods&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We recently added the ability to create pods via the &lt;code&gt;podman run&lt;/code&gt;&lt;/span&gt; and &lt;code&gt;podman create&lt;/code&gt; commands. One upside to creating a pod with this approach is that the normal port bindings declared for the container will be assigned automatically to the &amp;#8220;infra&amp;#8221; container. However, if you need to specify more granular options for pod creation like kernel namespaces or different &amp;#8220;infra&amp;#8221; container image usage, you still need to create the pod manually as was first described. Nevertheless, for relatively basic pod creations, the shortcut is handy. As this feature was recent added, it isn&amp;#8217;t available in the version of Podman included with Red Hat Enterprise Linux 7.6 and 8 Beta.&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;To create a new pod with your new container, you simply pass *&amp;#8211;pod*: &lt;code&gt;new:&amp;#60;name&amp;#62;&lt;/code&gt;.  The use of **new:** indicates to Podman that you want to create a new pod rather than attempt to assign the container to an existing pod.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;To create a nginx container within a pod and expose port 80 from the container to port 32597 on the host, you would:&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman run -dt --pod new:nginx -p 32597:80 quay.io/libpod/alpine_nginx:latest&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;ac8839fc7dead8e391e7983ad8d0c27ce311d190b0a8eb72dcde535de272d537&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ curl http://localhost:32597&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;podman rulez&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;And here is what it looks like when listing containers:&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman ps -ap&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS              &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAMES           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;ac8839fc7dea  quay.io/libpod/alpine_nginx:latest  nginx -g daemon o... 4 minutes ago Up 4 minutes ago                     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;happy_cray      &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3e4cad88f8c2&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;c2f7c5651275  k8s.gcr.io/pause:3.1                                  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;4 minutes ago Up 4 minutes ago  0.0.0.0:32597-&amp;#62;80/tcp  3e4cad88f8c2-infra 3e4cad88f8c2&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;MariaDB example&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The following asciinema demo shows how to create a pod via the shortcut method.  The container being run is a MariaDB container image and I bind only to its 127.0.0.1 address.  This means only containers in the same pod will able to access it. I then run an alpine container, install the MariaDB-client package, connect to the database itself, and show defined databases.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://asciinema.org/a/Xc818xXZ7TAlP9yvHU88IPVBK"&gt;&lt;img class="alignnone" src="https://asciinema.org/a/Xc818xXZ7TAlP9yvHU88IPVBK.svg" alt="" width="945" height="568" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Pods and container management&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;In Podman, the status of the pod and its containers can be exclusive to each other meaning that containers within pods can be restarted, stopped, and started without impacting the status of the pod.  Suppose we have a pod called &lt;code&gt;demodb&lt;/code&gt; and it contains two containers (and an “infra” container) running a MariaDB and a nginx session.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod ps&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS   INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196c   demodb Running   About a minute ago  3 &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3005ed8491d0&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman ps -p&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS  NAMES        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;02e37a3b9873  quay.io/libpod/alpine_nginx:latest   nginx -g daemon o... 4 minutes ago Up 4 minutes ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;optimistic_edison  fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;2597454063f8  quay.io/baude/mariadbpoddemo:latest  docker-entrypoint... 4 minutes ago Up 4 minutes ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;eloquent_golick&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;fa7924a5196c&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;If we wanted to stop and start the nginx container, the status of the MariaDB container and the pod itself will remain unchanged.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman stop optimistic_edison&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;02e37a3b987300e9124b61820119ae425c5e496b907800ecaf1194a3f50e5dcc&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;With the nginx container stopped, we can still observe the &lt;code&gt;demopod&lt;/code&gt; is running and the MariaDB container remains unchanged.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod ps&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS   INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196c   demodb Running   5 minutes ago 3           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3005ed8491d0&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman ps -p&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   C&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;REATED    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS  NAMES       &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;2597454063f8  quay.io/baude/mariadbpoddemo:latest  docker-entrypoint... 5 minutes ago Up 5 minutes ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;eloquent_golick  fa7924a5196c&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;And we can start the nginx container to restore the pod back to its original state.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman start optimistic_edison&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;optimistic_edison&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman ps -p&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS  NAMES        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;02e37a3b9873  quay.io/libpod/alpine_nginx:latest   nginx -g daemon o... 8 minutes ago Up 6 seconds ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;optimistic_edison  fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;2597454063f8  quay.io/baude/mariadbpoddemo:latest  docker-entrypoint... 8 minutes ago Up 8 minutes ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;eloquent_golick&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;fa7924a5196c&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We can also stop the pod and all of its containers using the &lt;code&gt;podman pod stop&lt;/code&gt; command.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod stop demodb&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196cb403298ad2ce24f0db30a3790e80729c7704ef5fdc27302f7ad0&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman ps -ap&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS                 &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS                &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAMES           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;02e37a3b9873  quay.io/libpod/alpine_nginx:latest   nginx -g daemon o... 10 minutes ago Exited (0) 21 seconds ago                       &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;optimistic_edison   fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;2597454063f8  quay.io/baude/mariadbpoddemo:latest  docker-entrypoint... 10 minutes ago Exited (0) 19 seconds ago                       &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;eloquent_golick &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;3005ed8491d0  k8s.gcr.io/pause:3.1                                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;10 minutes ago Exited (0) 19 seconds ago  0.0.0.0:43871-&amp;#62;3306/tcp fa7924a5196c-infra  fa7924a5196c&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;And if we look at the status of the pod, it will show a state of “Exited”.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod ps&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS   CREATED    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS   INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196c   demodb Exited   13 minutes ago 3           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3005ed8491d0&lt;/span&gt;&lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Likewise, we can also start the pod and all of its containers back up.  After which, all the containers in the pod should be running and the pod should show a status of “Running”.&lt;/span&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;pre&gt;&lt;span style="font-weight: 400;"&gt;$ sudo podman pod start demodb&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196cb403298ad2ce24f0db30a3790e80729c7704ef5fdc27302f7ad0&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman ps -p&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;CONTAINER ID  IMAGE                   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;COMMAND           &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;   &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS        &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;PORTS  NAMES         &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;POD&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;02e37a3b9873  quay.io/libpod/alpine_nginx:latest   nginx -g daemon o... 14 minutes ago Up 5 seconds ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;optimistic_edison  fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;2597454063f8  quay.io/baude/mariadbpoddemo:latest  docker-entrypoint... 14 minutes ago Up 4 seconds ago     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;eloquent_golick&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;fa7924a5196c&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;$ sudo podman pod ps&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;POD ID     &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;NAME &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;STATUS&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;CREATED      &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;  &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;# OF CONTAINERS  INFRA ID&lt;/span&gt; &lt;span style="font-weight: 400;"&gt;fa7924a5196c   demodb Running   14 minutes ago 3            &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;    &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;3005ed8491d0&lt;/span&gt; &lt;/pre&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;There is also a &lt;code&gt;podman pod restart&lt;/code&gt; command that will restart all the containers within a Pod.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Wrap up&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The ability for Podman to handle pod deployment is a clear differentiator to other container runtimes.  As a libpod maintainer, I am still realizing the advantages of having pods even in a localized runtime. There will most certainly be more development in Podman around pods as we learn how users exploit the use of them.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;For more information on Podman, make sure you visit the &lt;/span&gt;&lt;a href="https://github.com/containers/libpod"&gt;&lt;span style="font-weight: 400;"&gt;libpod project page&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; on github. Relevant blogs and news related to Podman can also be found at &lt;/span&gt;&lt;a href="https://podman.io/"&gt;&lt;span style="font-weight: 400;"&gt;podman.io&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Podman is included with Red Hat Enterprise Linux 7.6 as well as Red Hat Enterprise Linux 8 beta.&lt;/p&gt; &lt;h2&gt;More about Podman on the Red Hat Developer Blog&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/20/buildah-podman-containers-without-daemons/"&gt;Containers without daemons: Podman and Buildah available in RHEL 7.6 and RHEL 8 Beta&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools/"&gt;Podman &amp;#8211; The next generation of Linux container tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/08/29/intro-to-podman/"&gt;Intro to Podman (New in Red Hat Enterprise Linux 7.6)&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/11/29/managing-containerized-system-services-with-podman/"&gt;Managing containerized system services with Podman&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#38;linkname=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F01%2F15%2Fpodman-managing-containers-pods%2F&amp;#038;title=Podman%3A%20Managing%20pods%20and%20containers%20in%20a%20local%20container%20runtime" data-a2a-url="https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods/" data-a2a-title="Podman: Managing pods and containers in a local container runtime"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods/"&gt;Podman: Managing pods and containers in a local container runtime&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/SZB7t9TN_Oc" height="1" width="1" alt=""/&gt;</content><summary>People associate running pods with Kubernetes. And when they run containers in their development runtimes, they do not even think about the role pods could play—even in a localized runtime.  Most people coming from the Docker world of running single containers do not envision the concept of running pods. There are several good reasons to consider using pods locally, other than using pods to natura...</summary><dc:creator>Brent Baude</dc:creator><dc:date>2019-01-15T13:00:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/01/15/podman-managing-containers-pods/</feedburner:origLink></entry><entry><title>Infinispan Spring Boot Starter 2.1.2.Final is out!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/y0iEd3NHMSM/infinispan-spring-boot-starter-212final.html" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="infinispan" scheme="searchisko:content:tags" /><category term="minor release" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><category term="Spring" scheme="searchisko:content:tags" /><category term="spring-boot" scheme="searchisko:content:tags" /><category term="spring-boot starters" scheme="searchisko:content:tags" /><author><name>Katia Aresti</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_spring_boot_starter_2_1_2_final_is_out</id><updated>2019-01-15T09:52:09Z</updated><published>2019-01-15T09:52:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Dear Infinispan and Spring Boot users,&lt;br /&gt;&lt;br /&gt;We have just released &lt;a href="https://github.com/infinispan/infinispan-spring-boot" target="_blank"&gt;Infinispan Spring Boot&lt;/a&gt;&amp;nbsp;&lt;b&gt;2.1.2.Final&lt;/b&gt;.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;2.1.2.Final&lt;/b&gt; is using&amp;nbsp;&lt;b&gt;Spring Boot 2.1.2.RELEASE&lt;/b&gt;&amp;nbsp;and contains some bug fixes related to JCache and Actuator integration.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;The starter is now using Infinispan's&amp;nbsp;last stable release: &lt;b&gt;9.4.5.Final&lt;/b&gt;.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;You can find this release in the maven central repository.&lt;br /&gt;&lt;br /&gt;Please report any issues in our&amp;nbsp;&lt;a href="https://issues.jboss.org/projects/ISPN"&gt;issue tracker&lt;/a&gt;&amp;nbsp;and join the conversation in our&amp;nbsp;&lt;a href="https://infinispan.zulipchat.com/"&gt;Zulip Chat&lt;/a&gt;&amp;nbsp;to shape up our next release.&lt;br /&gt;&lt;br /&gt;Enjoy,&lt;br /&gt;&lt;br /&gt;The Infinispan Team&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/p38HKNZbYw8" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/y0iEd3NHMSM" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan and Spring Boot users, We have just released Infinispan Spring Boot 2.1.2.Final. 2.1.2.Final is using Spring Boot 2.1.2.RELEASE and contains some bug fixes related to JCache and Actuator integration. The starter is now using Infinispan's last stable release: 9.4.5.Final. You can find this release in the maven central repository. Please report any issues in our issue tracker and joi...</summary><dc:creator>Katia Aresti</dc:creator><dc:date>2019-01-15T09:52:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/p38HKNZbYw8/infinispan-spring-boot-starter-212final.html</feedburner:origLink></entry></feed>
